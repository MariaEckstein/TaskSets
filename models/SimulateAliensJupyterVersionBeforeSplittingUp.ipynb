{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datetime\n",
    "import glob\n",
    "import ipdb\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-colorblind')  # https://matplotlib.org/users/style_sheets.html\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import plotnine as gg\n",
    "gg.theme_set(gg.theme_bw)\n",
    "from scipy import stats\n",
    "from sklearn import manifold, decomposition, preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Statsmodels.OLS ( )\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from AlienTask import Task\n",
    "from shared_aliens import update_Qs_sim, get_alien_paths, get_alien_initial_q,\\\n",
    "    get_summary_initial_learn, get_summary_cloudy, simulate_competition_phase, simulate_rainbow_phase, get_summary_rainbow,\\\n",
    "    read_in_human_data, se, get_chosen_TS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define things\n",
    "do_isomap = False\n",
    "do_save_selected_agents = True\n",
    "if do_isomap:\n",
    "    from sklearn import manifold, decomposition, preprocessing\n",
    "\n",
    "# Which model will be simulated?\n",
    "model_name = 'Bayes'\n",
    "models = ['hier', 'Bayes', 'flat']\n",
    "n_sim_per_subj, n_subj = 1, 26  # n_sim_per_sub = 20, n_subj = 31 (version3.1)  # TODO should be 1, 31-x (1 sim per person; exclude excluded subjects)\n",
    "n_sim = n_sim_per_subj * n_subj\n",
    "n_actions, n_aliens, n_seasons, n_TS = 3, 4, 3, 3\n",
    "alien_initial_Q = get_alien_initial_q(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "## Where is human experimental data stored?\n",
    "human_data_path = get_alien_paths()[\"human data prepr\"]\n",
    "\n",
    "## Where will simulated summaries be saved or read in?\n",
    "summary_save_dir = os.path.join(get_alien_paths(False)['fitting results'], 'SummariesInsteadOfFitting_revision')\n",
    "full_summary_save_dir = os.path.join(summary_save_dir, 'FullSimulations')\n",
    "\n",
    "## Where will plots be saved that we create here?\n",
    "plot_save_dir = os.path.join(summary_save_dir, 'plots')  # 'C:/Users/maria/MEGAsync/Berkeley/TaskSets/paperplots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allowed parameter ranges to be sampled from\n",
    "def get_param_names_ranges(model_name):\n",
    "    \n",
    "    if model_name == 'hier':\n",
    "        param_names = ['alpha', 'beta', 'forget', 'alpha_high', 'beta_high', 'forget_high']\n",
    "        param_ranges = pd.DataFrame.from_dict(\n",
    "            {'alpha': [0, 1], 'beta': [1, 20], 'forget': [0, 1],\n",
    "             'alpha_high': [0, 1], 'beta_high': [1, 20], 'forget_high': [0, 1]\n",
    "             })\n",
    "\n",
    "    elif model_name == 'flat':\n",
    "        param_names = ['alpha', 'beta', 'forget']\n",
    "        param_ranges = pd.DataFrame.from_dict({'alpha': [0, 1], 'beta': [1, 20], 'forget': [0, 1]})\n",
    "\n",
    "    elif model_name == 'Bayes':\n",
    "        param_names = ['alpha', 'beta', 'forget', 'beta_high', 'forget_high']\n",
    "        param_ranges = pd.DataFrame.from_dict(\n",
    "            {'alpha': [0, 1], 'beta': [1, 20], 'forget': [0, 1],\n",
    "             'beta_high': [1, 20], 'forget_high': [0, 1]\n",
    "             })\n",
    "\n",
    "    else:\n",
    "        raise(NameError, 'model_name must be \"flat\", \"Bayes\", or \"hier\"!')\n",
    "        \n",
    "    return param_names, param_ranges\n",
    "\n",
    "# Example use\n",
    "param_names, param_ranges = get_param_names_ranges(model_name)\n",
    "param_names, param_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names for the simulation summary measures\n",
    "## Initial learning phase\n",
    "IL_cols = ['IL_saving_av', 'IL_saving_first_trial', 'IL_saving_last_trial',  # savings\n",
    "           'IL_acc_current_TS', 'IL_acc_prev_TS', 'IL_acc_other_TS',  # intrusion errors\n",
    "           'IL_acc_current_TS_se', 'IL_acc_prev_TS_se', 'IL_acc_other_TS_se',\n",
    "           'IL_perf_TS0', 'IL_perf_TS1', 'IL_perf_TS2',  # TS values\n",
    "           'IL_perf_TS0_se', 'IL_perf_TS1_se', 'IL_perf_TS2_se', 'IL_perf_TS_corr'\n",
    "           ]\n",
    "\n",
    "## Cloudy phase\n",
    "CL_cols = ['CL_acc_trial0', 'CL_acc_trial1', 'CL_acc_trial2', 'CL_acc_trial3',\n",
    "           'CL_acc_trial0_se', 'CL_acc_trial1_se', 'CL_acc_trial2_se', 'CL_acc_trial3_se',\n",
    "           'CL_slope', 'CL_slope_TS0', 'CL_slope_TS1', 'CL_slope_TS2']  # TS reactivation\n",
    "\n",
    "## Competition phase\n",
    "CO_cols = ['CO_acc_season', 'CO_acc_season_alien', 'CO_acc_season_se', 'CO_acc_season_alien_se']  # competition alien values & TS values\n",
    "\n",
    "## Rainbow phase\n",
    "RB_cols = ['RB_alien0_action0', 'RB_alien0_action1', 'RB_alien0_action2',\n",
    "           'RB_alien1_action0', 'RB_alien1_action1', 'RB_alien1_action2',\n",
    "           'RB_alien2_action0', 'RB_alien2_action1', 'RB_alien2_action2',\n",
    "           'RB_alien3_action0', 'RB_alien3_action1', 'RB_alien3_action2']\n",
    "RB_sum_cols = ['TS0', 'TS1', 'TS2', 'None', 'TS0_se', 'TS1_se', 'TS2_se', 'None_se']\n",
    "summary_dat_cols = param_names + IL_cols + CL_cols + CO_cols + RB_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create task, get numbers of trials for each phase\n",
    "task = Task(n_subj)\n",
    "n_trials, _, _, _, _ = task.get_trial_sequence(get_alien_paths(False)[\"human data prepr\"],\n",
    "                                         n_subj, n_sim_per_subj, range(n_subj),\n",
    "                                         phases=(\"1InitialLearning\", \"2CloudySeason\"))\n",
    "\n",
    "n_trials_ = {'1InitialLearn': np.sum(task.phase == '1InitialLearning'),\n",
    "             '2CloudySeason': np.sum(task.phase == '2CloudySeason'),\n",
    "             '4RainbowSeason': 4 * n_aliens,\n",
    "             '5Competition': 3}\n",
    "\n",
    "trials = {'1InitialLearn': range(n_trials_['1InitialLearn']),\n",
    "          '2CloudySeason': range(n_trials_['1InitialLearn'],\n",
    "                                 n_trials_['1InitialLearn'] + n_trials_['2CloudySeason'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_values(seasons, aliens, TS):\n",
    "    \"\"\"\n",
    "    Looks up objective action values and TS values for a numpy array of seasons and aliens, given a specific TS.\n",
    "    \"\"\"\n",
    "    return np.max(TS[seasons, aliens], axis=1)\n",
    "\n",
    "def get_TS_values(seasons, TS):\n",
    "    \"\"\"\n",
    "    Looks up objective action values and TS values for a numpy array of seasons and aliens, given a specific TS.\n",
    "    \"\"\"\n",
    "    return np.mean(np.max(TS[seasons], axis=2), axis=1)\n",
    "\n",
    "# Example use\n",
    "s, a = np.array([0, 1, 2]), np.array([0, 0, 0])\n",
    "s, a = [0, 1, 2], [0, 0, 0]\n",
    "get_action_values(s, a, task.TS), get_TS_values(s, task.TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate summaries\n",
    "def get_summary(parameters, param_ranges, n_sim, n_subj, model, summary_or_fulldata='summary'):\n",
    "\n",
    "    # Get parmaeters\n",
    "    ## Scale parameters correctly\n",
    "    parameters = param_ranges.loc[0] + (param_ranges.loc[1] - param_ranges.loc[0]) * parameters\n",
    "\n",
    "    beta_shape = (n_sim, 1)  # Q_low_sub.shape -> [n_subj, n_actions]\n",
    "    beta_high_shape = (n_sim, 1)  # Q_high_sub.shape -> [n_subj, n_TS]\n",
    "    forget_shape = (n_sim, 1, 1, 1)  # Q_low[0].shape -> [n_subj, n_TS, n_aliens, n_actions]\n",
    "    forget_high_shape = (n_sim, 1, 1)  # -> [n_subj, n_seasons, n_TS]\n",
    "\n",
    "    ## Parameters present in all models (flat RL, hier RL, Bayes)\n",
    "    alpha = parameters['alpha'] * np.ones(n_sim)\n",
    "    beta = parameters['beta'] * np.ones(beta_shape)\n",
    "    forget = parameters['forget'] * np.ones(forget_shape)\n",
    "\n",
    "    ## Deal with parameters that exist only in some models\n",
    "    try:\n",
    "        alpha_high = parameters['alpha_high'] * np.ones(n_sim)\n",
    "    except KeyError:\n",
    "        alpha_high = np.zeros(n_sim)\n",
    "    try:\n",
    "        beta_high = parameters['beta_high'] * np.ones(beta_high_shape)\n",
    "    except KeyError:\n",
    "        beta_high = np.zeros(beta_high_shape)\n",
    "    try:\n",
    "        forget_high = parameters['forget_high'] * np.ones(forget_high_shape)\n",
    "    except KeyError:\n",
    "        forget_high = np.zeros(forget_high_shape)\n",
    "        \n",
    "    # Initial learning phase\n",
    "    ## Set up data storage\n",
    "    seasons = np.zeros([n_trials, n_sim], dtype=int)\n",
    "    corrects = np.zeros([n_trials, n_sim])\n",
    "    rewards = np.zeros([n_trials, n_sim])\n",
    "    aliens = np.zeros([n_trials, n_sim], dtype=int)\n",
    "    actions = np.zeros([n_trials, n_sim], dtype=int)\n",
    "    TSs = []\n",
    "\n",
    "    ## Inialize Q-values\n",
    "    Q_low = alien_initial_Q * np.ones([n_sim, n_TS, n_aliens, n_actions])\n",
    "    Q_high = alien_initial_Q * np.ones([n_sim, n_seasons, n_TS])\n",
    "\n",
    "    ## Simulate behavior\n",
    "    for trial in trials['1InitialLearn']:\n",
    "\n",
    "        ### Observe stimuli\n",
    "        season, alien = task.present_stimulus(trial)\n",
    "\n",
    "        ### Select action & update Q-values\n",
    "        [Q_low, Q_high, TS, action, correct, reward, p_low] =\\\n",
    "            update_Qs_sim(season, alien,\n",
    "                          Q_low, Q_high,\n",
    "                          beta, beta_high, alpha, alpha_high, forget, forget_high,\n",
    "                          n_sim, n_actions, n_TS, task, alien_initial_Q, model_name)\n",
    "        \n",
    "        ### Store trial data\n",
    "        seasons[trial] = season\n",
    "        corrects[trial] = correct\n",
    "        rewards[trial] = reward\n",
    "        aliens[trial] = alien\n",
    "        actions[trial] = action\n",
    "        TSs += [TS]\n",
    "\n",
    "    ## Save final Q-values for subsequent phases\n",
    "    final_Q_low = Q_low.copy()\n",
    "    final_Q_high = Q_high.copy()\n",
    "    ipdb.set_trace()\n",
    "\n",
    "    ## Calculate summaries for initial learning phase\n",
    "    summary_initial_learn = get_summary_initial_learn(\n",
    "        seasons[trials['1InitialLearn']], corrects[trials['1InitialLearn']],\n",
    "        aliens[trials['1InitialLearn']], actions[trials['1InitialLearn']],\n",
    "        n_seasons, n_sim, trials, task)\n",
    "\n",
    "    # Cloudy season\n",
    "    cloudy_season = 0\n",
    "    for trial in trials['2CloudySeason']:\n",
    "\n",
    "        ## Observe trial stimuli\n",
    "        old_season = season.copy()\n",
    "        season, alien = task.present_stimulus(trial)\n",
    "\n",
    "        ## Season switches\n",
    "        if trial == list(trials['2CloudySeason'])[0]:\n",
    "            season_switches = np.ones(n_sim, dtype=bool)\n",
    "        else:\n",
    "            season_switches = season != old_season\n",
    "            \n",
    "        ## Reset Q-values after each season switch to previously memorized values\n",
    "        if (model_name == 'hier') or (model_name == 'Bayes'):\n",
    "            Q_high_mem = np.max(final_Q_high, axis=1)  # [n_sim, TS] \"memorized\" correct TS in each season\n",
    "            Q_high[season_switches] = alien_initial_Q  # not necessary, but looks cleaner\n",
    "            Q_high[season_switches, cloudy_season] = Q_high_mem[season_switches]  # n_sim, n_seasons, n_TS\n",
    "\n",
    "        elif model_name == 'flat':\n",
    "            Q_low_mem = np.mean(final_Q_low, axis=1)  # [n_sim, n_aliens, n_actions] \"memorized\" overall task strategy\n",
    "            Q_low[season_switches] = alien_initial_Q  # not necessary, but looks cleaner\n",
    "            Q_low[season_switches, cloudy_season] = Q_low_mem[season_switches]\n",
    "        \n",
    "        else:\n",
    "            raise(NameError, 'Model_name must be \"flat\", \"hier\", or \"Bayes\".')\n",
    "\n",
    "        ## Update Q-values\n",
    "        [Q_low, Q_high, TS, action, correct, reward, p_low] =\\\n",
    "            update_Qs_sim(cloudy_season * season, alien,\n",
    "                          Q_low, Q_high,\n",
    "                          beta, beta_high, alpha, alpha_high, forget, forget_high,\n",
    "                          n_sim, n_actions, n_TS, task, alien_initial_Q, model_name)\n",
    "\n",
    "        ## Store trial data\n",
    "        seasons[trial] = season\n",
    "        corrects[trial] = correct\n",
    "        rewards[trial] = reward\n",
    "        aliens[trial] = alien\n",
    "        actions[trial] = action\n",
    "        TSs += [TS]\n",
    "    TSs = np.array(TSs)\n",
    "\n",
    "    ## Calculate summaries for cloudy phase\n",
    "    summary_cloudy = get_summary_cloudy(\n",
    "        seasons[trials['2CloudySeason']], corrects[trials['2CloudySeason']],\n",
    "        aliens[trials['2CloudySeason']], actions[trials['2CloudySeason']],\n",
    "        n_sim, task)\n",
    "    \n",
    "    # Run and get summaries for competition phase\n",
    "    comp_data = simulate_competition_phase(model_name, final_Q_high, final_Q_low, task,\n",
    "                                           n_seasons, n_aliens, n_sim, beta_high, n_blocks_comp=n_trials_['5Competition'])\n",
    "    summary_competition = comp_data.groupby('phase').aggregate('mean').reset_index()[['perc_selected_better', 'se']].T.values.flatten()\n",
    "    summary_competition = pd.DataFrame(data=summary_competition, index=CO_cols)\n",
    "    \n",
    "    # Run and get summaries for rainbow season\n",
    "    rainbow_dat = simulate_rainbow_phase(n_seasons, model_name, n_sim,\n",
    "                                         beta, beta_high, final_Q_low, final_Q_high)\n",
    "    rainbow_dat = pd.DataFrame(data=rainbow_dat.flatten(), index=RB_cols)\n",
    "    \n",
    "    # Run regression models for initial learn and cloudy\n",
    "    regr_coefs = run_regr_models(\n",
    "        seasons, corrects, aliens, actions, trials, regr_phases = ['1InitialLearn', '2CloudySeason'])\n",
    "\n",
    "    # Return list of summaries\n",
    "    if summary_or_fulldata == 'summary':\n",
    "        return pd.concat(\n",
    "            [parameters, summary_initial_learn, summary_cloudy, summary_competition, rainbow_dat, regr_coefs])\n",
    "    elif summary_or_fulldata == 'fulldata':\n",
    "        return seasons, corrects, rewards, aliens, actions, TSs\n",
    "    else:\n",
    "        raise ValueError('summary_or_fulldata must either be \"summary\" or \"fulldata\".')\n",
    "        \n",
    "# Example use\n",
    "params = np.random.rand(len(param_names))\n",
    "get_summary(params, param_ranges, n_sim, n_subj, model_name, summary_or_fulldata='fulldata')\n",
    "get_summary(params, param_ranges, n_sim, n_subj, model_name, summary_or_fulldata='summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regr_models(seasons, corrects, aliens, actions, trials, regr_phases = ['1InitialLearn', '2CloudySeason']):\n",
    "    \n",
    "    \"\"\"\n",
    "    Run the regression correct ~ action_value + TS_value, separately for each participant\n",
    "    Return mean and std over participants.\n",
    "    \"\"\"\n",
    "    \n",
    "    regr_coefs = []\n",
    "    for phase in regr_phases:\n",
    "\n",
    "        # Get data\n",
    "        seasons_ph, corrects_ph, aliens_ph, actions_ph = seasons[\n",
    "            trials[phase]], corrects[trials[phase]], aliens[trials[phase]], actions[trials[phase]]\n",
    "        c = corrects_ph.astype(int)\n",
    "        Qa = np.array([get_action_values(seasons_ph[trial], aliens_ph[trial], task.TS)\n",
    "                       for trial in range(len(seasons_ph))])  # trial x subj\n",
    "        Qts = np.array([get_TS_values(seasons_ph[trial], task.TS)\n",
    "                        for trial in range(len(seasons_ph))])  # trial x subj\n",
    "\n",
    "        # Run model for each agent\n",
    "        coefs = []\n",
    "        for subj in range(c.shape[1]):\n",
    "            c_subj = c[:, subj]\n",
    "            Qa_subj = Qa[:, subj]\n",
    "            Qts_subj = Qts[:, subj]\n",
    "\n",
    "            X_subj = np.array([Qa_subj, Qts_subj]).T\n",
    "            y_subj = c[:, subj]\n",
    "\n",
    "            X_subj, y_subj\n",
    "\n",
    "            regr = LogisticRegression(solver='lbfgs')\n",
    "            regr.fit(X_subj, y_subj)\n",
    "            coefs += [regr.coef_.flatten()]\n",
    "\n",
    "        coefs = pd.DataFrame(\n",
    "            data=np.concatenate([np.mean(np.array(coefs), axis=0), np.std(np.array(coefs), axis=0)]),\n",
    "            index=['{}_{}{}'.format(q, p, s) for q, p, s in zip(2 * ['Qa', 'Qts'], 4 * [phase], 2 * ['_mean'] + 2 * ['_se'])])\n",
    "        regr_coefs += [coefs]\n",
    "\n",
    "    return pd.concat(regr_coefs, axis=0)\n",
    "\n",
    "# Example use\n",
    "params = np.random.rand(len(param_names))\n",
    "seasons, corrects, rewards, aliens, actions, TSs = get_summary(\n",
    "            params, param_ranges, n_sim, n_subj, model_name, summary_or_fulldata='fulldata')\n",
    "run_regr_models(seasons, corrects, aliens, actions, trials, regr_phases = ['1InitialLearn', '2CloudySeason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_frequency = 20\n",
    "print_frequency = 20\n",
    "n_frames = 100\n",
    "n_sims_per_frame = 1000\n",
    "\n",
    "# Get summaries for different parameters\n",
    "new_time = time.time()\n",
    "\n",
    "for frame_i in range(n_frames):\n",
    "    summaries = pd.DataFrame()\n",
    "\n",
    "    for sim_i in range(n_sims_per_frame):\n",
    "        params = np.random.rand(len(param_names))\n",
    "        new_summary = get_summary(\n",
    "            params, param_ranges, n_sim, n_subj, model_name, summary_or_fulldata='summary')\n",
    "        summaries = pd.concat([summaries, new_summary], axis=1)\n",
    "\n",
    "        if (sim_i % print_frequency) == 0:\n",
    "\n",
    "            # Print progress\n",
    "            print(\"\\n\\tIteration {}\".format(sim_i))\n",
    "            old_time = new_time\n",
    "            new_time = time.time()\n",
    "            diff = new_time - old_time\n",
    "            print(\"Time passed: {} seconds\".format(np.round(diff)))\n",
    "\n",
    "        if ((sim_i % save_frequency) == 0) or (sim_i == n_sims_per_frame - 1):\n",
    "\n",
    "            # Save summaries to disk\n",
    "            save_path = os.path.join(summary_save_dir, model_name + '_summaries_{}TEST.csv'.format(frame_i))\n",
    "            save_summaries = summaries.T\n",
    "            save_summaries['model'] = model_name\n",
    "            save_summaries.to_csv(save_path)\n",
    "            print(\"Saving summaries to {}\".format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in simulation summaries and vizualize as density plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get human data\n",
    "n_hum, hum_aliens, hum_seasons, hum_corrects, hum_actions, hum_rewards, hum_rainbow_dat, hum_comp_dat = read_in_human_data(\n",
    "    human_data_path, 828, n_aliens, n_actions, exclude=['160',])  # '164' -> already excluded for head trauma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get human initial learn data\n",
    "hum_summary_initial_learn = get_summary_initial_learn(\n",
    "    hum_seasons[trials['1InitialLearn']], hum_corrects[trials['1InitialLearn']],\n",
    "    hum_aliens[trials['1InitialLearn']], hum_actions[trials['1InitialLearn']],\n",
    "    n_seasons, n_hum, trials, task).T\n",
    "\n",
    "hum_summary_initial_learn['IL_saving_last_minus_first'] = hum_summary_initial_learn['IL_saving_last_trial'] - hum_summary_initial_learn['IL_saving_first_trial']\n",
    "hum_summary_initial_learn['IL_perf_TS0_minus_TS1'] = hum_summary_initial_learn['IL_perf_TS0'] - hum_summary_initial_learn['IL_perf_TS1']\n",
    "hum_summary_initial_learn['IL_perf_TS0_minus_TS2'] = hum_summary_initial_learn['IL_perf_TS0'] - hum_summary_initial_learn['IL_perf_TS2']\n",
    "hum_summary_initial_learn['IL_perf_TS1_minus_TS2'] = hum_summary_initial_learn['IL_perf_TS1'] - hum_summary_initial_learn['IL_perf_TS2']\n",
    "\n",
    "hum_summary_initial_learn['IL_first_TS0_minus_TS2'] = hum_summary_initial_learn['IL_first_TS0'] - hum_summary_initial_learn['IL_first_TS2']\n",
    "hum_summary_initial_learn['IL_first_TS0_minus_TS1'] = hum_summary_initial_learn['IL_first_TS0'] - hum_summary_initial_learn['IL_first_TS1']\n",
    "hum_summary_initial_learn['IL_first_TS1_minus_TS2'] = hum_summary_initial_learn['IL_first_TS1'] - hum_summary_initial_learn['IL_first_TS2']\n",
    "\n",
    "# Get human cloudy data\n",
    "hum_summary_cloudy = get_summary_cloudy(\n",
    "    hum_seasons[trials['2CloudySeason']], hum_corrects[trials['2CloudySeason']],\n",
    "    hum_aliens[trials['2CloudySeason']], hum_actions[trials['2CloudySeason']],\n",
    "    n_hum, task).T\n",
    "hum_summary_cloudy['CL_first_TS0_minus_TS2'] = hum_summary_cloudy['CL_first_TS0'] - hum_summary_cloudy['CL_first_TS2']\n",
    "hum_summary_cloudy['CL_first_TS0_minus_TS1'] = hum_summary_cloudy['CL_first_TS0'] - hum_summary_cloudy['CL_first_TS1']\n",
    "hum_summary_cloudy['CL_first_TS1_minus_TS2'] = hum_summary_cloudy['CL_first_TS1'] - hum_summary_cloudy['CL_first_TS2']\n",
    "\n",
    "hum_summary_cloudy['CL_slope_TS0minusTS2'] = hum_summary_cloudy['CL_slope_TS0'] - hum_summary_cloudy['CL_slope_TS2']\n",
    "hum_summary_cloudy['CL_slope_TS0minusTS1'] = hum_summary_cloudy['CL_slope_TS0'] - hum_summary_cloudy['CL_slope_TS1']\n",
    "hum_summary_cloudy['CL_slope_TS1minusTS2'] = hum_summary_cloudy['CL_slope_TS1'] - hum_summary_cloudy['CL_slope_TS2']\n",
    "\n",
    "# Get human competition data\n",
    "season_cols = [col for col in hum_comp_dat.columns.values if col[0] == \"(\"]\n",
    "alien_cols = [col for col in hum_comp_dat.columns.values if col[0] != \"(\"]\n",
    "season_perf = np.mean(hum_comp_dat[season_cols], axis=1)\n",
    "alien_perf = np.mean(hum_comp_dat[alien_cols], axis=1)\n",
    "season_mean = np.mean(season_perf)\n",
    "season_se = np.std(season_perf) / np.sqrt(n_hum)\n",
    "alien_mean = np.mean(alien_perf)\n",
    "alien_se = np.std(alien_perf) / np.sqrt(n_hum)\n",
    "comp_t, comp_p = stats.ttest_rel(season_perf, alien_perf)\n",
    "hum_summary_competition = pd.DataFrame(np.array([[season_mean, alien_mean, season_se, alien_se, np.mean(season_perf-alien_perf)]]),\n",
    "                                       columns=CO_cols + ['CO_season_minus_alien'])\n",
    "\n",
    "# Get human rainbow data\n",
    "# hum_rainbow_dat = pd.DataFrame(np.expand_dims(hum_rainbow_dat.flatten(), axis=0), columns=RB_cols)\n",
    "hum_summary_rainbow = get_summary_rainbow(\n",
    "    n_aliens, n_seasons, hum_rainbow_dat, task)\n",
    "hum_summary_rainbow = pd.DataFrame(\n",
    "    data=np.expand_dims(hum_summary_rainbow, axis=0),\n",
    "    columns=RB_sum_cols)\n",
    "hum_summary_rainbow['TS0_minus_TS1'] = hum_summary_rainbow['TS0'] - hum_summary_rainbow['TS1']\n",
    "hum_summary_rainbow['TS0_minus_TS2'] = hum_summary_rainbow['TS0'] - hum_summary_rainbow['TS2']\n",
    "hum_summary_rainbow['TS1_minus_TS2'] = hum_summary_rainbow['TS1'] - hum_summary_rainbow['TS2']\n",
    "\n",
    "# Get regression models\n",
    "hum_regr_coefs = run_regr_models(\n",
    "    hum_seasons, hum_corrects, hum_aliens, hum_actions, trials, regr_phases = ['1InitialLearn', '2CloudySeason']).T\n",
    "for phase in ['1InitialLearn', '2CloudySeason']:\n",
    "    hum_regr_coefs['Qts_minus_a_{}'.format(phase)] = \\\n",
    "        hum_regr_coefs['Qts_{}_mean'.format(phase)] - hum_regr_coefs['Qa_{}_mean'.format(phase)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get agent summary filenames\n",
    "filenames = glob.glob(os.path.join(summary_save_dir, '*.csv'))\n",
    "filenames = [filename for filename in filenames if 'summar' in filename]  # don't read in selected_agents.csv etc.\n",
    "print('Found {} files.'.format(len(filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all csv with summaries\n",
    "all_summaries = pd.DataFrame(columns=param_names)\n",
    "for filename in filenames:\n",
    "    summaries = pd.read_csv(filename, index_col=0)\n",
    "    summaries = summaries.dropna()  # remove empty rows\n",
    "    all_summaries = all_summaries.append(summaries)\n",
    "all_summaries = all_summaries.reset_index(drop=True)\n",
    "\n",
    "# Add other measures\n",
    "all_summaries['IL_saving_last_minus_first'] = all_summaries['IL_saving_last_trial'] - all_summaries['IL_saving_first_trial']\n",
    "all_summaries['IL_perf_TS0_minus_TS1'] = all_summaries['IL_perf_TS0'] - all_summaries['IL_perf_TS1']\n",
    "all_summaries['IL_perf_TS0_minus_TS2'] = all_summaries['IL_perf_TS0'] - all_summaries['IL_perf_TS2']\n",
    "all_summaries['IL_perf_TS1_minus_TS2'] = all_summaries['IL_perf_TS1'] - all_summaries['IL_perf_TS2']\n",
    "\n",
    "all_summaries['CO_season_minus_alien'] = all_summaries['CO_acc_season'] - all_summaries['CO_acc_season_alien']\n",
    "all_summaries['IL_first_TS0_minus_TS2'] = all_summaries['IL_first_TS0'] - all_summaries['IL_first_TS2']\n",
    "all_summaries['IL_first_TS0_minus_TS1'] = all_summaries['IL_first_TS0'] - all_summaries['IL_first_TS1']\n",
    "all_summaries['IL_first_TS1_minus_TS2'] = all_summaries['IL_first_TS1'] - all_summaries['IL_first_TS2']\n",
    "\n",
    "all_summaries['CL_first_TS0_minus_TS2'] = all_summaries['CL_first_TS0'] - all_summaries['CL_first_TS2']\n",
    "all_summaries['CL_first_TS0_minus_TS1'] = all_summaries['CL_first_TS0'] - all_summaries['CL_first_TS1']\n",
    "all_summaries['CL_first_TS1_minus_TS2'] = all_summaries['CL_first_TS1'] - all_summaries['CL_first_TS2']\n",
    "\n",
    "all_summaries['CL_slope_TS0minusTS2'] = all_summaries['CL_slope_TS0'] - all_summaries['CL_slope_TS2']\n",
    "all_summaries['CL_slope_TS0minusTS1'] = all_summaries['CL_slope_TS0'] - all_summaries['CL_slope_TS1']\n",
    "all_summaries['CL_slope_TS1minusTS2'] = all_summaries['CL_slope_TS1'] - all_summaries['CL_slope_TS2']\n",
    "\n",
    "for phase in ['1InitialLearn', '2CloudySeason']:\n",
    "    all_summaries['Qts_minus_a_{}'.format(phase)] = \\\n",
    "        all_summaries['Qts_{}_mean'.format(phase)] - all_summaries['Qa_{}_mean'.format(phase)]\n",
    "\n",
    "print(\"Number of samples: {} (flat: {}; hier: {}; Bayes: {})\".\n",
    "      format(all_summaries.shape[0],\n",
    "             np.sum(all_summaries['model'] == 'flat'),\n",
    "             np.sum(all_summaries['model'] == 'hier'),\n",
    "             np.sum(all_summaries['model'] == 'Bayes')\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rainbow summary\n",
    "summary_rainbow = pd.DataFrame()\n",
    "for model in models:\n",
    "    rainbow_dat = all_summaries.loc[all_summaries['model'] == model, RB_cols]\n",
    "    rainbow_dat = rainbow_dat.values.reshape((rainbow_dat.shape[0], n_aliens, n_actions))\n",
    "    \n",
    "    summary_rainbow_mod = np.array([get_summary_rainbow(n_aliens, n_seasons, dat, task) for dat in rainbow_dat])\n",
    "    summary_rainbow_mod = pd.DataFrame(summary_rainbow_mod, columns=RB_sum_cols)\n",
    "    summary_rainbow_mod.loc[:, 'model'] = model\n",
    "    \n",
    "    cor = np.array([np.corrcoef(hum_rainbow_dat[0].flatten(), dat.flatten())[0, 1] for dat in rainbow_dat.astype(float)])\n",
    "    summary_rainbow_mod.loc[:, 'corr_with_humans'] = cor\n",
    "    \n",
    "    summary_rainbow = summary_rainbow.append(summary_rainbow_mod)\n",
    "    \n",
    "summary_rainbow['TS0_minus_TS1'] = summary_rainbow['TS0'] - summary_rainbow['TS1']\n",
    "summary_rainbow['TS0_minus_TS2'] = summary_rainbow['TS0'] - summary_rainbow['TS2']\n",
    "summary_rainbow['TS1_minus_TS2'] = summary_rainbow['TS1'] - summary_rainbow['TS2']\n",
    "summary_rainbow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot correlations and histograms\n",
    "for model_name in models:\n",
    "    model_summaries = all_summaries.loc[all_summaries['model'] == model_name]\n",
    "    model_summaries = model_summaries.reset_index(drop=True)\n",
    "    pd.plotting.scatter_matrix(model_summaries.loc[:1000, ['alpha', 'beta', 'forget']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_means_sds(sim_dat, hum_dat, column, t_compare_value=0):\n",
    "    \n",
    "    means_sds = sim_dat.groupby(\"model\")[column].agg(\n",
    "        {'mean': 'mean',\n",
    "         'std': 'std',\n",
    "         'lik': lambda x: np.mean(x > hum_dat[column][0]),\n",
    "         'lik2': lambda x: np.mean(x < hum_dat[column][0])})\n",
    "    \n",
    "    ttests = sim_dat.groupby('model')[column].agg(stats.ttest_1samp, t_compare_value)\n",
    "    \n",
    "    return means_sds, ttests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_difference_data(dat1, dat2, n_bins=50):\n",
    "    \n",
    "    dat_both = np.append(dat1, dat2)\n",
    "    \n",
    "    min_bin, max_bin = min(dat_both), max(dat_both)\n",
    "    \n",
    "    hist1, bins1 = np.histogram(dat1, range=(min_bin, max_bin), bins=n_bins)\n",
    "    hist2, bins2 = np.histogram(dat2, range=(min_bin, max_bin), bins=n_bins)\n",
    "    assert np.all(bins1 == bins2)\n",
    "    \n",
    "    diff = hist2 - hist1\n",
    "    \n",
    "    diff_dat = pd.DataFrame({'diff': diff,\n",
    "                             'bin': bins1[:-1]})\n",
    "\n",
    "    return diff_dat\n",
    "\n",
    "# Example usage\n",
    "nbins = 50\n",
    "phase = '1InitialLearn'\n",
    "\n",
    "dat_flat = all_summaries.loc[all_summaries.model=='flat', 'Qts_{}_mean'.format(phase)].values\n",
    "dat_hier = all_summaries.loc[all_summaries.model=='hier', 'Qts_{}_mean'.format(phase)].values\n",
    "\n",
    "get_difference_data(dat_flat, dat_hier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusable histogram function for all histogram plots\n",
    "def make_histogram(sim_dat, hum_dat, col_name, figure_size=(5, 2),\n",
    "                   xlim=None, ylim=None, vline=0, plot_name='test.png'):\n",
    "    \n",
    "    gg.options.figure_size = figure_size\n",
    "    g = (gg.ggplot(sim_dat, gg.aes(col_name, color='model'))\n",
    "     + gg.geom_density()\n",
    "     + gg.xlab(col_name)\n",
    "     + gg.scale_color_manual(['green', 'orange', 'blue'])\n",
    "     + gg.geom_vline(xintercept=hum_dat[col_name], color='red')\n",
    "     + gg.geom_vline(xintercept=vline, linetype='dotted')\n",
    "     + gg.coord_cartesian(xlim=xlim, ylim=ylim)\n",
    "    )\n",
    "    save_path = os.path.join(plot_save_dir, plot_name)\n",
    "    print(\"Saving to {}.\".format(save_path))\n",
    "    g.draw()\n",
    "    g.save(save_path)\n",
    "\n",
    "# Example use\n",
    "plot_name_base = '0TS_react_hist'\n",
    "make_histogram(all_summaries, hum_summary_cloudy, CL_cols[8], xlim=(-0.1, 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_diff_hist(sim_dat, hum_dat, col_name, model_names, figure_size = (4, 3),\n",
    "                   plot_name='test.png', n_bins=40, vline=0, xlim=None, ylim=None):\n",
    "\n",
    "    all_diff_dat = pd.DataFrame()\n",
    "\n",
    "    for model1_name, model2_name in model_names:\n",
    "        dat1 = sim_dat.loc[sim_dat.model==model1_name, col_name].values\n",
    "        dat2 = sim_dat.loc[sim_dat.model==model2_name, col_name].values\n",
    "\n",
    "        diff_dat = get_difference_data(dat1, dat2, n_bins=n_bins)\n",
    "        diff_dat['measure'] = col_name\n",
    "        diff_dat['models'] = ' minus '.join([model2_name, model1_name])\n",
    "\n",
    "        all_diff_dat = all_diff_dat.append(diff_dat)\n",
    "\n",
    "    gg.options.figure_size = figure_size\n",
    "    g = (gg.ggplot(all_diff_dat, gg.aes('bin', 'diff', color='models'))\n",
    "     + gg.geom_line()\n",
    "     + gg.xlab(col_name)\n",
    "     + gg.ylab('Difference (# samples)')\n",
    "     + gg.scale_color_manual(['green', 'orange'])\n",
    "     + gg.geom_vline(xintercept=hum_dat[col_name], color='red')\n",
    "     + gg.geom_vline(xintercept=vline, linetype='dotted')\n",
    "     + gg.coord_cartesian(xlim=xlim, ylim=ylim)\n",
    "    )\n",
    "    save_path = os.path.join(plot_save_dir, plot_name)\n",
    "    print(\"Saving to {}.\".format(save_path))\n",
    "    g.draw()\n",
    "    g.save(save_path)\n",
    "    \n",
    "# Example use\n",
    "model_names = [['flat', 'hier'], ['Bayes', 'hier']]\n",
    "col_name = 'Qts_1InitialLearn_mean'\n",
    "make_diff_hist(all_summarise, hum_summary_initial_learn, col_name, model_names, xlim=(-0.3, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Which TS are used initially (first four trials, initial learning phase)?\n",
    "plot_name_base = '2TS_values_regression'\n",
    "\n",
    "for phase in ['1InitialLearn', '2CloudySeason']:\n",
    "    cols = ['Qts_{}_mean'.format(phase), 'Qa_{}_mean'.format(phase)]\n",
    "\n",
    "    for colname in cols:\n",
    "        xlim = (-0.1, 0.25)\n",
    "        make_histogram(all_summaries, hum_regr_coefs,\n",
    "                       colname, xlim=xlim, ylim=(0, 15),\n",
    "                       plot_name='{}_{}_hist.png'.format(plot_name_base, colname))\n",
    "\n",
    "        make_diff_hist(all_summaries, hum_regr_coefs, colname, model_names, xlim=xlim,\n",
    "                       plot_name='{}_{}_diff.png'.format(plot_name_base, colname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reactivation of TS (cloudy)\n",
    "plot_name_base = '0TS_react_hist'\n",
    "\n",
    "for colname in CL_cols[8:] + ['CL_slope_TS1minusTS2', 'CL_slope_TS0minusTS2', 'CL_slope_TS0minusTS1']:\n",
    "    xlim = (-0.2, 0.4)\n",
    "    make_histogram(all_summaries, hum_summary_cloudy, colname,\n",
    "                   plot_name='{}_{}_hist.png'.format(plot_name_base, colname),\n",
    "                   xlim=xlim)\n",
    "\n",
    "    make_diff_hist(all_summaries, hum_summary_cloudy, colname, model_names, n_bins=18,\n",
    "                   plot_name='{}_{}_diff.png'.format(plot_name_base, colname),\n",
    "                   xlim=xlim)\n",
    "    \n",
    "# print(get_means_sds(all_summaries, hum_summary_cloudy, 'CL_slope'))\n",
    "# print(get_means_sds(all_summaries, hum_summary_cloudy, 'CL_slope_TS1minusTS2'))\n",
    "# print(get_means_sds(all_summaries, hum_summary_cloudy, 'CL_slope_TS0minusTS2'))\n",
    "# print(get_means_sds(all_summaries, hum_summary_cloudy, 'CL_slope_TS0minusTS1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Intrusion errors (init. learn.)\n",
    "plot_name_base = '1intrusion_errors_hist'\n",
    "\n",
    "for colname in IL_cols[3:5]:\n",
    "    xlim = (0.2, 0.5)\n",
    "    make_histogram(all_summaries, hum_summary_initial_learn, colname,\n",
    "                   plot_name='{}_{}_hist.png'.format(plot_name_base, colname),\n",
    "                   xlim=xlim, vline=1/3)\n",
    "\n",
    "    make_diff_hist(all_summaries, hum_summary_initial_learn, colname, model_names, n_bins=20,\n",
    "                   plot_name='{}_{}_diff.png'.format(plot_name_base, colname),\n",
    "                   xlim=xlim, vline=1/3)\n",
    "\n",
    "# print(get_means_sds(all_summaries, hum_summary_initial_learn, IL_cols[3], 1/3))\n",
    "# print(get_means_sds(all_summaries, hum_summary_initial_learn, IL_cols[4], 1/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TS values affect preference (competition)\n",
    "plot_name_base = '3TS_values_preference_hist'\n",
    "\n",
    "for colname in CO_cols[:2]:\n",
    "    xlim = (0.45, 0.7)\n",
    "    make_histogram(all_summaries, hum_summary_competition, colname,\n",
    "                   plot_name='{}_{}_hist.png'.format(plot_name_base, colname),\n",
    "                   xlim=xlim, vline=1/2)\n",
    "    \n",
    "    make_diff_hist(all_summaries, hum_summary_competition, colname, model_names,\n",
    "                   plot_name='{}_{}_diff.png'.format(plot_name_base, colname),\n",
    "                   xlim=xlim, vline=1/2)\n",
    "\n",
    "colname = 'CO_season_minus_alien'\n",
    "xlim = (-0.1, 0.1)\n",
    "make_histogram(all_summaries, hum_summary_competition, colname,\n",
    "               plot_name='{}_{}_hist.png'.format(plot_name_base, col_name),\n",
    "               xlim=xlim)\n",
    "\n",
    "make_diff_hist(all_summaries, hum_summary_competition, colname, model_names,\n",
    "               plot_name='{}_{}_diff.png'.format(plot_name_base, col_name),\n",
    "               xlim=xlim)\n",
    "\n",
    "# get_means_sds(all_summaries, hum_summary_competition, 'CO_season_minus_alien')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TS values affect generalization (rainbow)\n",
    "plot_name_base = '2TS_rainbow'\n",
    "\n",
    "for colname in ['TS0_minus_TS2', 'TS0_minus_TS1', 'TS1_minus_TS2']:\n",
    "    xlim = (-0.02, 0.15)\n",
    "    make_histogram(summary_rainbow, hum_summary_rainbow, colname,\n",
    "                   plot_name='{}_{}_hist.png'.format(plot_name_base, colname),\n",
    "                   xlim=xlim, ylim=(0, 30))\n",
    "\n",
    "    make_diff_hist(summary_rainbow, hum_summary_rainbow, colname, model_names,\n",
    "                   plot_name='{}_{}_diff.png'.format(plot_name_base, colname), xlim=xlim)\n",
    "    \n",
    "# print(get_means_sds(summary_rainbow, hum_summary_rainbow, 'TS0_minus_TS2'))\n",
    "# print(get_means_sds(summary_rainbow, hum_summary_rainbow, 'TS0_minus_TS1'))\n",
    "# print(get_means_sds(summary_rainbow, hum_summary_rainbow, 'TS1_minus_TS2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_name_base = '4TS_values'\n",
    "for colname in ['IL_first_TS0_minus_TS2', 'IL_first_TS0_minus_TS1', 'IL_first_TS1_minus_TS2']:\n",
    "    xlim = (-0.01, 0.15)\n",
    "    make_histogram(all_summaries, hum_summary_initial_learn, colname,\n",
    "                   plot_name='{}_{}_hist.png'.format(plot_name_base, colname),\n",
    "                   xlim=xlim)\n",
    "    \n",
    "    make_diff_hist(all_summaries, hum_summary_initial_learn, colname, model_names, n_bins=15,\n",
    "                   plot_name='{}_{}_diff.png'.format(plot_name_base, colname),\n",
    "                   xlim=xlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_name_base = '5TS_values'\n",
    "for colname in ['CL_first_TS0_minus_TS2', 'CL_first_TS0_minus_TS1', 'CL_first_TS1_minus_TS2']:\n",
    "    xlim = (-0.01, 0.15)\n",
    "    make_histogram(all_summaries, hum_summary_cloudy, colname,\n",
    "                   plot_name='{}_{}_hist.png'.format(plot_name_base, colname),\n",
    "                   xlim=xlim)\n",
    "    \n",
    "    make_diff_hist(all_summaries, hum_summary_cloudy, colname, model_names, n_bins=15,\n",
    "                   plot_name='{}_{}_diff.png'.format(plot_name_base, colname),\n",
    "                   xlim=xlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TS values affect generalization (rainbow)\n",
    "fig, axes = plt.subplots(nrows=len(models), figsize=(8, 8))\n",
    "colors = sns.cubehelix_palette(4, start=.5, rot=-.75, reverse=True)[:-1]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    dat = summary_rainbow.loc[summary_rainbow['model'] == model]\n",
    "\n",
    "    # Plot\n",
    "    for j, effect in enumerate(RB_sum_cols[:3]):\n",
    "        sns.distplot(dat[effect], kde=True, hist=False, label=effect, color=colors[j], ax=axes[i])\n",
    "        [ax.axvline(x=10/12/3, color='grey', linestyle='--') for ax in axes[:2]]\n",
    "        [ax.set_xlim(0, 0.5) for ax in axes[:2]]\n",
    "        [ax.set_ylim(0, 100) for ax in axes[:2]]\n",
    "        axes[i].set_title(model)\n",
    "        [ax.set_xlabel(\"\") for ax in axes]\n",
    "        axes[i].legend()\n",
    "\n",
    "[ax.set_ylabel(\"Density\") for ax in axes]\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_save_dir + '/4TS_values_generalization_hist2.png')\n",
    "# get_means_sds(summary_rainbow, hum_summary_rainbow, 'TS0_minus_TS2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rainbow phase TS choices\n",
    "plt.figure()\n",
    "for model in models:\n",
    "\n",
    "    # Get summary_rainbow\n",
    "    rainbow_dat = all_summaries.loc[all_summaries['model'] == model, RB_cols]\n",
    "    rainbow_dat = rainbow_dat.values.reshape((rainbow_dat.shape[0], n_aliens, n_actions))\n",
    "    summary_rainbow = np.array([get_summary_rainbow(n_aliens, n_seasons, dat, task) for dat in rainbow_dat])\n",
    "    summary_rainbow = pd.DataFrame(summary_rainbow, columns=RB_sum_cols)\n",
    "\n",
    "    # Plot\n",
    "    for i, effect in enumerate(RB_sum_cols[:3]):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        sns.distplot(summary_rainbow[effect], kde=True, hist=True, label=model)\n",
    "        plt.axvline(x=10/12/3, color='grey', linestyle='--')\n",
    "        plt.axvline(x=hum_summary_rainbow[effect].values, color='red', linestyle='-')\n",
    "        plt.xlim(0, 0.5)\n",
    "        plt.ylim(0, 60)\n",
    "        plt.xlabel(effect)\n",
    "        plt.ylabel(\"Density\")\n",
    "\n",
    "    effect = RB_sum_cols[3]\n",
    "    plt.subplot(2, 3, 4)\n",
    "    sns.distplot(summary_rainbow[effect], kde=True, hist=True, label=model)\n",
    "    plt.axvline(x=(2/12), color='grey', linestyle='--')\n",
    "    plt.axvline(x=hum_summary_rainbow[effect].values, color='red', linestyle='-')\n",
    "    plt.xlim(0, 0.5)\n",
    "    plt.ylim(0, 60)\n",
    "    plt.xlabel(effect)\n",
    "    plt.ylabel(\"Density\")\n",
    "\n",
    "    effect = 'TS0_minus_TS2'\n",
    "    plt.subplot(2, 3, 5)\n",
    "    sns.distplot(summary_rainbow[effect], kde=True, hist=True, label=model)\n",
    "    plt.axvline(x=0, color='grey', linestyle='--')\n",
    "    plt.axvline(x=hum_summary_rainbow[effect].values, color='red', linestyle='-')\n",
    "    plt.xlim(-0.3, 0.3)\n",
    "    plt.ylim(0, 60)\n",
    "    plt.xlabel(effect)\n",
    "    plt.ylabel(\"Density\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Savings (init. learn.)\n",
    "make_histogram(all_summaries,\n",
    "               hum_summary_initial_learn, IL_cols[:3] + ['IL_saving_last_minus_first'],\n",
    "               plot_name='5Savings_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot paramter - marker correlations\n",
    "hum_sums = hum_summary_initial_learn[['IL_acc_prev_TS', 'IL_acc_current_TS', 'IL_perf_TS0_minus_TS1']]\n",
    "hum_sums['CL_slope'] = hum_summary_cloudy['CL_slope']\n",
    "hum_sums['CO_season_minus_alien'] = hum_summary_competition['CO_season_minus_alien']\n",
    "markers = ['CL_slope', 'IL_acc_current_TS', 'IL_acc_prev_TS', 'IL_perf_TS0_minus_TS1', 'CO_season_minus_alien']\n",
    "\n",
    "for model, params in zip(models, [param_names[:3], param_names]):\n",
    "\n",
    "    # Correlations between markers and parameters\n",
    "    dat = all_summaries.loc[all_summaries['model'] == model]\n",
    "    sns.pairplot(dat, x_vars=params, y_vars=markers, kind='reg',\n",
    "             plot_kws={'color': 'grey', 'fit_reg': False, 'scatter_kws': {'s': 1}})\n",
    "    plt.savefig(os.path.join(plot_save_dir, '/CorrMarkerParam_{}.png'.format(model))\n",
    "\n",
    "    # Correlations between different markers\n",
    "    sns.pairplot(dat, vars=markers, kind='reg',\n",
    "                 plot_kws={'color': 'grey', 'fit_reg': False, 'scatter_kws': {'s': 1}},\n",
    "                 diag_kind='kde', diag_kws={'color': 'grey', 'shade': True})\n",
    "    # add human data\n",
    "    # plt.scatter(hum_sums)\n",
    "    plt.savefig(os.path.join(plot_save_dir, '/CorrParamParam_{}.png'.format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find good simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_agents(width):\n",
    "    lower = (10 - width/2) / 10\n",
    "    upper = (10 + width/2) / 10\n",
    "\n",
    "    # Get masks for each effects\n",
    "    IL_acc_prev_TS = (\n",
    "            all_summaries['IL_acc_prev_TS'] > lower * hum_summary_initial_learn['IL_acc_prev_TS'].values[0]) & (\n",
    "            all_summaries['IL_acc_prev_TS'] < upper * hum_summary_initial_learn['IL_acc_prev_TS'].values[0])\n",
    "    IL_acc_current_TS = (\n",
    "            all_summaries['IL_acc_current_TS'] > lower * hum_summary_initial_learn['IL_acc_current_TS'].values[0]) & (\n",
    "            all_summaries['IL_acc_current_TS'] < upper * hum_summary_initial_learn['IL_acc_current_TS'].values[0])\n",
    "    CO_acc_season = (\n",
    "            all_summaries['CO_acc_season'] > lower * hum_summary_competition['CO_acc_season'].values[0]) & (\n",
    "            all_summaries['CO_acc_season'] < upper * hum_summary_competition['CO_acc_season'].values[0])\n",
    "    CO_acc_season_alien = (\n",
    "            all_summaries['CO_acc_season_alien'] > lower * hum_summary_competition['CO_acc_season_alien'].values[0]) & (\n",
    "            all_summaries['CO_acc_season_alien'] < upper * hum_summary_competition['CO_acc_season_alien'].values[0])\n",
    "    CL_slope = (\n",
    "            all_summaries['CL_slope'] > lower * hum_summary_cloudy['CL_slope'].values[0]) & (\n",
    "            all_summaries['CL_slope'] < upper * hum_summary_cloudy['CL_slope'].values[0])\n",
    "    Qts_1InitialLearn_mean = (\n",
    "            all_summaries['Qts_1InitialLearn_mean'] > lower * hum_regr_coefs['Qts_1InitialLearn_mean'].values[0]) & (\n",
    "            all_summaries['Qts_1InitialLearn_mean'] < upper * hum_regr_coefs['Qts_1InitialLearn_mean'].values[0])\n",
    "    Qa_1InitialLearn_mean = (\n",
    "            all_summaries['Qa_1InitialLearn_mean'] > lower * hum_regr_coefs['Qa_1InitialLearn_mean'].values[0]) & (\n",
    "            all_summaries['Qa_1InitialLearn_mean'] < upper * hum_regr_coefs['Qa_1InitialLearn_mean'].values[0])\n",
    "\n",
    "    # Subset data\n",
    "    selected_agents = all_summaries.loc[\n",
    "        IL_acc_prev_TS & IL_acc_current_TS & CO_acc_season & CO_acc_season_alien & CL_slope\n",
    "        & Qts_1InitialLearn_mean & Qa_1InitialLearn_mean\n",
    "    ]  # IL_acc_prev_TS & CL_slope & CO_season_minus_alien & IL_perf_TS2minus1\n",
    "\n",
    "    # Count models\n",
    "    model_ns = [selected_agents.loc[selected_agents['model'] == model,].shape[0] for model in models]\n",
    "\n",
    "    return selected_agents, model_ns\n",
    "\n",
    "# Example use\n",
    "get_selected_agents(6)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How many models do we get depending on width of interval?\n",
    "widths = np.arange(0, 50)\n",
    "\n",
    "all_ns = []\n",
    "for width in widths:\n",
    "    selected_agents, model_ns = get_selected_agents(width)\n",
    "    all_ns += [model_ns + [lower, upper, width]]\n",
    "\n",
    "all_ns = pd.DataFrame(data=all_ns, columns=['n_{}'.format(m) for m in models] + ['lower', 'upper', 'width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_ns_long = pd.melt(all_ns, id_vars=('lower', 'upper', 'width'), var_name='model', value_name='n')\n",
    "all_ns_long['log_n'] = np.log(all_ns_long['n'])\n",
    "\n",
    "print(gg.ggplot(all_ns_long, gg.aes('width', 'n', color='model'))\n",
    " + gg.geom_point()\n",
    " + gg.geom_vline(xintercept=10)\n",
    ")\n",
    "print(gg.ggplot(all_ns_long, gg.aes('width', 'log_n', color='model'))\n",
    " + gg.geom_point()\n",
    " + gg.geom_vline(xintercept=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select agents for one width\n",
    "selected_agents, model_ns = get_selected_agents(width=10)\n",
    "print(\"Found {} agents: {}, {}\".format(selected_agents.shape[0], models, model_ns))\n",
    "\n",
    "# Save selected_agents as csv\n",
    "if do_save_selected_agents:\n",
    "    save_path = summary_save_dir + '/selected_agents.csv'\n",
    "    print(\"Saving selected_agents to {}\".format(save_path))\n",
    "    selected_agents.to_csv(save_path, index=False)\n",
    "\n",
    "for model in ['hier', 'flat']:\n",
    "    sub_dat = selected_agents.loc[selected_agents['model'] == model]\n",
    "    sub_dat[['beta', 'beta_high']] /= 20\n",
    "    if model == 'flat':\n",
    "        param_names_ = param_names[:3]\n",
    "    else:\n",
    "        param_names_ = param_names\n",
    "    sub_dat[param_names_].plot(kind='box', by='model')\n",
    "    scatter_matrix(sub_dat[param_names_])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_params = selected_agents[param_names + ['model']]\n",
    "\n",
    "# # par_long = pd.melt(selected_params, id_vars='model', var_name='param_name', value_name='param_value')\n",
    "# # print(gg.ggplot(par_long, gg.aes('param_name', 'param_value', color='model'))\n",
    "# #  + gg.geom_boxplot()\n",
    "# # )  JUST TOO SLOW\n",
    "\n",
    "# sim_params = selected_params.groupby('model').aggregate('median').reset_index()\n",
    "# sim_params['alpha_high'] = np.nan\n",
    "# sim_params.loc[sim_params['model'] == 'hier', 'alpha_high'] = np.median(\n",
    "#     selected_params.loc[selected_params['model'] == 'hier', 'alpha_high'])\n",
    "# sim_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create task, get numbers of trials for each phase\n",
    "n_sim_per_subj, n_subj = 10, 26  # n_sim_per_sub = 20, n_subj = 31 (version3.1)  # TODO should be 1, 31-x (1 sim per person; exclude excluded subjects)\n",
    "task = Task(n_subj)\n",
    "n_trials, _, _, _, _ = task.get_trial_sequence(get_alien_paths(False)[\"human data prepr\"],\n",
    "                                         n_subj, n_sim_per_subj, range(n_subj),\n",
    "                                         phases=(\"1InitialLearning\", \"2CloudySeason\"))\n",
    "\n",
    "n_trials_ = {'1InitialLearn': np.sum(task.phase == '1InitialLearning'),\n",
    "             '2CloudySeason': np.sum(task.phase == '2CloudySeason'),\n",
    "             '4RainbowSeason': 4 * n_aliens,\n",
    "             '5Competition': 3}\n",
    "\n",
    "trials = {'1InitialLearn': range(n_trials_['1InitialLearn']),\n",
    "          '2CloudySeason': range(n_trials_['1InitialLearn'],\n",
    "                                 n_trials_['1InitialLearn'] + n_trials_['2CloudySeason'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'hier'\n",
    "\n",
    "param_names, param_ranges = get_param_names_ranges(model_name)\n",
    "selected_params = selected_agents[param_names + ['model']]\n",
    "sim_params = selected_params.groupby('model').aggregate('median').reset_index()\n",
    "sim_params['alpha_high'] = np.nan\n",
    "sim_params.loc[sim_params['model'] == 'hier', 'alpha_high'] = np.median(\n",
    "    selected_params.loc[selected_params['model'] == 'hier', 'alpha_high'])\n",
    "\n",
    "# Simulate one full dataset\n",
    "## Get parameters\n",
    "params_0inf = sim_params.loc[sim_params['model'] == model_name]\n",
    "params_0inf = params_0inf.drop(columns=['model'])\n",
    "params_0inf = params_0inf.reindex(param_names, axis=1)\n",
    "\n",
    "params_01 = (params_0inf - param_ranges.loc[0]) / (param_ranges.loc[1] - param_ranges.loc[0])\n",
    "param_values = params_01.values.flatten()\n",
    "\n",
    "## Simulate\n",
    "n_sim = n_sim_per_subj * n_subj\n",
    "print(\"Simulating {} {} agents with parameters:\\n{}\\n\".format(n_sim, model_name, params_0inf))\n",
    "sim_summary = get_summary(\n",
    "    param_values, param_ranges, n_sim, n_subj, model_name, summary_or_fulldata='summary')\n",
    "sim_summary[:40], sim_summary[40:]\n",
    "sim_summary = sim_summary.T\n",
    "sim_summary['model'] = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Simulate\n",
    "# print(\"Simulating {} {} agents with parameters:\\n{}\\n\".format(n_sim, model_name, params_0inf))\n",
    "# seasons, corrects, rewards, aliens, actions, TSs = get_summary(\n",
    "#     param_values, param_ranges, n_sim, n_subj, model_name, summary_or_fulldata='fulldata')\n",
    "\n",
    "# ## Save individual agents to disk like humans\n",
    "# for agentID in range(n_sim):\n",
    "\n",
    "#     # Create pandas DataFrame\n",
    "#     subj_data = pd.DataFrame()\n",
    "#     subj_data[\"context\"] = seasons[:, agentID]\n",
    "#     subj_data[\"sad_alien\"] = aliens[:, agentID]\n",
    "#     subj_data[\"item_chosen\"] = actions[:, agentID]\n",
    "#     subj_data[\"reward\"] = rewards[:, agentID]\n",
    "#     subj_data[\"correct\"] = corrects[:, agentID]\n",
    "#     subj_data[\"trial_type\"] = \"feed-aliens\"\n",
    "#     subj_data[\"trial_index\"] = np.arange(n_trials)\n",
    "#     subj_data[\"subjID\"] = agentID\n",
    "#     subj_data[\"block.type\"] = \"normal\"\n",
    "#     subj_data[\"model_name\"] = model_name\n",
    "#     subj_data[\"phase\"] = ['1InitialLearning'] * n_trials_['1InitialLearn'] + ['2CloudySeason'] * n_trials_['2CloudySeason']\n",
    "#     for i, param_name in enumerate(param_names):\n",
    "#         subj_data[param_name] = param_values[i]\n",
    "\n",
    "#     # Save to disc\n",
    "#     file_name = \"{}/aliens_{}_ag{}_modelidx{}.csv\".format(\n",
    "#         full_summary_save_dir, model_name, agentID, 'median')\n",
    "#     print('Saving file {0}'.format(file_name))\n",
    "#     subj_data.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot bar graphs for humans and agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot human behavior & selected_agents\n",
    "def make_plot(hum_mean, ag_mean, hum_se=False, ag_se=False, plot_name=\"plot.png\", ylabel=\"\",\n",
    "              hline=False, ylim=False, xlabel=\"\", xticklabels=False, figsize=(8,4), plotted_models=models):\n",
    "\n",
    "    if not np.any(hum_se):\n",
    "        hum_se = np.zeros(len(hum_mean.T))\n",
    "    if not np.any(ag_se):\n",
    "        ag_se = np.zeros(3)\n",
    "    if not xticklabels:\n",
    "        xticklabels = \"\"\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=4, figsize=figsize)\n",
    "    [ax.set_title(title) for ax, title in zip(axes, ['Humans'] + models)]\n",
    "\n",
    "    axes[0].bar(range(len(hum_mean)), hum_mean, yerr=hum_se, tick_label=xticklabels, color='grey')\n",
    "    for i_model in range(len(plotted_models)):\n",
    "        axes[i_model+1].bar(range(len(hum_mean)), ag_mean[i_model], yerr=ag_se[i_model],\n",
    "                          tick_label=xticklabels, color='grey')\n",
    "\n",
    "    [ax.set_ylabel(ylabel) for ax in axes]\n",
    "    [ax.set_xlabel(xlabel) for ax in axes]\n",
    "\n",
    "    if ylim:\n",
    "        [ax.set_ylim(ylim) for ax in axes]\n",
    "    if hline:\n",
    "        [ax.axhline(y=hline, color='black', linestyle='--') for ax in axes]\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_save_dir + plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get agent data\n",
    "# model_idx = 0\n",
    "# bar_models = ['hier', 'flat']\n",
    "\n",
    "# selected_agents = pd.read_csv(summary_save_dir + '/selected_agents.csv', index_col=0)\n",
    "# selected_agents = selected_agents.reset_index()\n",
    "# ag_summary = pd.DataFrame(\n",
    "#     [selected_agents.loc[selected_agents['model'] == model\n",
    "#                         ].reset_index(drop=True).loc[min(model_ns[i]-1, model_idx)]\n",
    "#      for i, model in zip([0, 2], bar_models)]\n",
    "#     )\n",
    "\n",
    "# save_dir = summary_save_dir + 'ag_summary_for_paper.csv'\n",
    "# ag_summary.to_csv(save_dir)\n",
    "# print(\"Saving agents used for paper plots to {}!\".format(save_dir))\n",
    "# ag_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ag_summary_rainbow = pd.DataFrame()\n",
    "# ag_rainbow_dat = list()\n",
    "\n",
    "# for model in bar_models:\n",
    "#     model_dat = ag_summary.loc[ag_summary['model'] == model, RB_cols]\n",
    "#     mod_ag_rainbow_dat = model_dat.values.reshape((n_aliens, n_actions))\n",
    "#     mod_ag_summary_rainbow = get_summary_rainbow(n_aliens, n_seasons, mod_ag_rainbow_dat, task)\n",
    "#     mod_ag_summary_rainbow = pd.DataFrame(\n",
    "#         data=np.expand_dims(mod_ag_summary_rainbow, axis=0),\n",
    "#         columns=RB_sum_cols)\n",
    "    \n",
    "#     ag_summary_rainbow = ag_summary_rainbow.append(mod_ag_summary_rainbow)\n",
    "#     ag_rainbow_dat.append(mod_ag_rainbow_dat)\n",
    "    \n",
    "# ag_summary_rainbow['TS1minusTS2'] = ag_summary_rainbow['TS1'] - ag_summary_rainbow['TS2']\n",
    "# ag_summary_rainbow['TS0minusTS2'] = ag_summary_rainbow['TS0'] - ag_summary_rainbow['TS2']\n",
    "# ag_summary_rainbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_summary_rainbow = pd.DataFrame()\n",
    "sim_rainbow_dat = list()\n",
    "\n",
    "for model in ['hier']:\n",
    "    model_dat = sim_summary.loc[sim_summary['model'] == model, RB_cols]\n",
    "    mod_sim_rainbow_dat = model_dat.values.reshape((n_aliens, n_actions))\n",
    "    mod_sim_summary_rainbow = get_summary_rainbow(n_aliens, n_seasons, mod_sim_rainbow_dat, task)\n",
    "    mod_sim_summary_rainbow = pd.DataFrame(\n",
    "        data=np.expand_dims(mod_sim_summary_rainbow, axis=0),\n",
    "        columns=RB_sum_cols)\n",
    "    \n",
    "    sim_summary_rainbow = sim_summary_rainbow.append(mod_sim_summary_rainbow)\n",
    "    sim_rainbow_dat.append(mod_sim_rainbow_dat)\n",
    "    \n",
    "sim_summary_rainbow['TS1minusTS2'] = sim_summary_rainbow['TS1'] - sim_summary_rainbow['TS2']\n",
    "sim_summary_rainbow['TS0minusTS2'] = sim_summary_rainbow['TS0'] - sim_summary_rainbow['TS2']\n",
    "sim_summary_rainbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot intrusion errors\n",
    "make_plot(hum_summary_initial_learn[IL_cols[3:5]].values.flatten(), sim_summary[IL_cols[3:5]].values,\n",
    "          hum_summary_initial_learn[IL_cols[6:8]].values.flatten(), sim_summary[IL_cols[6:8]].values,\n",
    "          plot_name='1intrusion_errors_{}.png'.format(model_idx), figsize=(8, 4),\n",
    "          ylabel=\"Fraction (trial 1)\", hline=1/3, ylim=(0, 0.5), xticklabels=['Acc.', 'Intr.err.'],\n",
    "          plotted_models=['hier',])\n",
    "\n",
    "# # Plot TS values affect performance\n",
    "# make_plot(hum_summary_initial_learn[IL_cols[10:12]].values.flatten(), sim_summary[IL_cols[10:12]].values,\n",
    "#           hum_summary_initial_learn[IL_cols[13:15]].values.flatten(), sim_summary[IL_cols[13:15]].values,\n",
    "#           plot_name='2TS_values_perf_{}.png.'.format(model_idx), figsize=(8, 4),\n",
    "#           ylabel=\"TS performance\", hline=1/3, ylim=(1/3, 0.65), xticklabels=['TS2', 'TS1'],\n",
    "#           plotted_models=['hier',])\n",
    "\n",
    "# # Plot Savings\n",
    "# make_plot(hum_summary_initial_learn[IL_cols[:3]].values.flatten(), sim_summary[IL_cols[:3]].values,\n",
    "#           plot_name='5Savings.png', figsize=(12, 4),\n",
    "#           ylabel=\"Savings\", xticklabels=IL_cols[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot TS reactivation\n",
    "make_plot(hum_summary_cloudy[CL_cols[:4]].values.flatten(), sim_summary[CL_cols[:4]].values,\n",
    "          hum_summary_cloudy[CL_cols[4:8]].values.flatten(), sim_summary[CL_cols[4:8]].values,\n",
    "          plot_name='0TS_react_{}.png'.format(model_idx), figsize=(12, 4),\n",
    "          ylabel=\"% correct\", hline=False, ylim=(0, 0.45),\n",
    "          xlabel=\"Trial\", xticklabels=range(1, n_aliens+1),\n",
    "          plotted_models=['hier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS values affect preference\n",
    "make_plot(hum_summary_competition[CO_cols[:2]].values.flatten(), sim_summary[CO_cols[:2]].values,\n",
    "          hum_summary_competition[CO_cols[2:4]].values.flatten(), sim_summary[CO_cols[2:4]].values,\n",
    "          plot_name='3TS_values_preference_{}.png'.format(model_idx), figsize=(8, 4),\n",
    "          ylabel=\"frac. better chosen\", hline=1/2, ylim=(0, 0.7), xticklabels=['Context', 'Stimulus'],\n",
    "          plotted_models=['hier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot TS values affect generalization\n",
    "make_plot(hum_summary_rainbow[RB_sum_cols[:4]].values.flatten(), sim_summary_rainbow[RB_sum_cols[:4]].values,\n",
    "          hum_summary_rainbow[RB_sum_cols[4:8]].values.flatten(),\n",
    "          plot_name='4TS_values_generalization_{}.png'.format(model_idx), figsize=(12, 4),\n",
    "          ylabel='% TS selected', ylim=(0, 0.5), xticklabels=['TS3', 'TS2', 'TS1', 'No-TS'],\n",
    "          plotted_models=['hier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rainbow phase correlation between human and simulated actions\n",
    "# rb_cor = np.corrcoef(hum_rainbow_dat[0].flatten(), ag_rainbow_dat.astype(float).flatten())[0, 1]\n",
    "# stats.pearsonr(hum_rainbow_dat[0].flatten(), ag_rainbow_dat.astype(float).flatten())\n",
    "\n",
    "# Rainbow phase action heatmaps\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(12, 4))\n",
    "# plt.suptitle('Correlation between humans & simulation: {}'.format(rb_cor.round(3)))\n",
    "[ax.set_title(title) for ax, title in zip(axes, ['Humans'] + ['hier'])]\n",
    "cax1 = axes[0].matshow(hum_rainbow_dat[0])\n",
    "for i in range(len(['hier'])):\n",
    "    axes[i+1].matshow(pd.DataFrame(ag_rainbow_dat[i]).astype(float))\n",
    "[ax.set_xlabel('Action') for ax in axes]\n",
    "[ax.set_ylabel('Stimulus') for ax in axes]\n",
    "# fig.colorbar(cax1)\n",
    "\n",
    "# # Show values of correct actions in rainbow phase\n",
    "# correct_TS = task.TS.copy().astype(float)\n",
    "# correct_TS[correct_TS == 1] = np.nan\n",
    "# av_Q_correct_action = np.nanmean(correct_TS, axis=0)\n",
    "# av_Q_correct_action[np.isnan(av_Q_correct_action)] = 0\n",
    "# axes[1].set_title(\"Values correct actions\")\n",
    "# axes[1].matshow(av_Q_correct_action)\n",
    "# for (i, j), z in np.ndenumerate(av_Q_correct_action):\n",
    "#     axes[1].text(j, i, '{:0.1f}'.format(z), ha='center', va='center')\n",
    "# axes[0].set_xlabel('Aliens')\n",
    "# axes[0].set_ylabel('Actions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_parameters(parameters, param_ranges):\n",
    "    \n",
    "    ## Scale parameters correctly\n",
    "    parameters = param_ranges.loc[0] + (param_ranges.loc[1] - param_ranges.loc[0]) * parameters\n",
    "\n",
    "    beta_shape = (n_sim, 1)  # Q_low_sub.shape -> [n_subj, n_actions]\n",
    "    beta_high_shape = (n_sim, 1)  # Q_high_sub.shape -> [n_subj, n_TS]\n",
    "    forget_shape = (n_sim, 1, 1, 1)  # Q_low[0].shape -> [n_subj, n_TS, n_aliens, n_actions]\n",
    "    forget_high_shape = (n_sim, 1, 1)  # -> [n_subj, n_seasons, n_TS]\n",
    "\n",
    "    ## Parameters present in all models (flat RL, hier RL, Bayes)\n",
    "    alpha = parameters['alpha'] * np.ones(n_sim)\n",
    "    beta = parameters['beta'] * np.ones(beta_shape)\n",
    "    forget = parameters['forget'] * np.ones(forget_shape)\n",
    "\n",
    "    ## Deal with parameters that exist only in some models\n",
    "    try:\n",
    "        alpha_high = parameters['alpha_high'] * np.ones(n_sim)\n",
    "    except KeyError:\n",
    "        alpha_high = np.zeros(n_sim)\n",
    "    try:\n",
    "        beta_high = parameters['beta_high'] * np.ones(beta_high_shape)\n",
    "    except KeyError:\n",
    "        beta_high = np.zeros(beta_high_shape)\n",
    "    try:\n",
    "        forget_high = parameters['forget_high'] * np.ones(forget_high_shape)\n",
    "    except KeyError:\n",
    "        forget_high = np.zeros(forget_high_shape)\n",
    "\n",
    "    return alpha, beta, forget, alpha_high, beta_high, forget_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_initial_learn(n_trials, n_sim, n_TS, n_aliens, n_actions, n_seasons,\n",
    "                           alpha, beta, forget, alpha_high, beta_high, forget_high,\n",
    "                           alien_initial_Q, trials, task):\n",
    "    \n",
    "    ## Set up data storage\n",
    "    seasons = np.zeros([n_trials, n_sim], dtype=int)\n",
    "    corrects = np.zeros([n_trials, n_sim])\n",
    "    rewards = np.zeros([n_trials, n_sim])\n",
    "    aliens = np.zeros([n_trials, n_sim], dtype=int)\n",
    "    actions = np.zeros([n_trials, n_sim], dtype=int)\n",
    "\n",
    "    ## Inialize Q-values\n",
    "    Q_low = alien_initial_Q * np.ones([n_sim, n_TS, n_aliens, n_actions])\n",
    "    Q_high = alien_initial_Q * np.ones([n_sim, n_seasons, n_TS])\n",
    "\n",
    "    ## Simulate behavior\n",
    "    for trial in trials['1InitialLearn']:\n",
    "\n",
    "        ### Observe stimuli\n",
    "        season, alien = task.present_stimulus(trial)\n",
    "\n",
    "        ### Select action & update Q-values\n",
    "        [Q_low, Q_high, TS, action, correct, reward, p_low] =\\\n",
    "            update_Qs_sim(season, alien,\n",
    "                          Q_low, Q_high,\n",
    "                          beta, beta_high, alpha, alpha_high, forget, forget_high,\n",
    "                          n_sim, n_actions, n_TS, task, alien_initial_Q, model_name)\n",
    "\n",
    "        ### Store trial data\n",
    "        seasons[trial] = season\n",
    "        corrects[trial] = correct\n",
    "        rewards[trial] = reward\n",
    "        aliens[trial] = alien\n",
    "        actions[trial] = action\n",
    "\n",
    "    return Q_low, Q_high, seasons, corrects, rewards, aliens, actions, season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_cloudy(trials, season, task):\n",
    "\n",
    "    for trial in trials['2CloudySeason']:\n",
    "\n",
    "        ## Observe trial stimuli\n",
    "        old_season = season.copy()\n",
    "        season, alien = task.present_stimulus(trial)\n",
    "\n",
    "        ## Season switches\n",
    "        if trial == list(trials['2CloudySeason'])[0]:\n",
    "            season_switches = np.ones(n_sim, dtype=bool)\n",
    "        else:\n",
    "            season_switches = season != old_season\n",
    "\n",
    "        ## Reset Q-values after season switches\n",
    "        if (model_name == 'hier') or (model_name == 'Bayes'):\n",
    "            Q_high[season_switches] = alien_initial_Q  # re-start search for the right TS when season changes\n",
    "        elif model_name == 'flat':\n",
    "            Q_low[season_switches] = alien_initial_Q  # re-learn a new policy from scratch when season changes\n",
    "        else:\n",
    "            raise(NameError, 'Model_name must be \"flat\", \"hier\", or \"Bayes\".')\n",
    "\n",
    "        ## Update Q-values\n",
    "        [Q_low, Q_high, TS, action, correct, reward, p_low] =\\\n",
    "            update_Qs_sim(0 * season, alien,\n",
    "                          Q_low, Q_high,\n",
    "                          beta, beta_high, alpha, alpha_high, forget, forget_high,\n",
    "                          n_sim, n_actions, n_TS, task, alien_initial_Q, model_name)\n",
    "\n",
    "        ## Store trial data\n",
    "        seasons[trial] = season\n",
    "        corrects[trial] = correct\n",
    "        rewards[trial] = reward\n",
    "        aliens[trial] = alien\n",
    "        actions[trial] = action\n",
    "\n",
    "    return seasons, corrects, aliens, actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = np.random.rand(len(param_names))\n",
    "# params[-1] = 0\n",
    "# params[-2] = 0\n",
    "final_Q_low, final_Q_high, Q_high_mem = get_summary(\n",
    "    params, param_ranges, n_sim, n_subj, model_name, summary_or_fulldata='summary')\n",
    "\n",
    "np.mean(np.mean(final_Q_high, axis=0), axis=1)\n",
    "final_Q_high\n",
    "# Q_high_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# seasons, corrects, rewards, aliens, actions, TSs = get_summary(\n",
    "#     params, param_ranges, n_sim, n_subj, model_name, summary_or_fulldata='fulldata')\n",
    "\n",
    "# # Subset cloudy season\n",
    "# phase_initial='CL'\n",
    "# seasons, corrects, aliens, actions, TSs = seasons[trials['2CloudySeason']], corrects[trials['2CloudySeason']], aliens[trials['2CloudySeason']], actions[trials['2CloudySeason']], TSs[trials['2CloudySeason']]\n",
    "    \n",
    "# # Get season changes\n",
    "# season_changes = np.array([seasons[i, 0] != seasons[i + 1, 0] for i in range(len(seasons)-1)])\n",
    "# season_changes = np.insert(season_changes, 0, False)\n",
    "\n",
    "# # Get first four trials after context switch\n",
    "# alien_sum = np.array([i // 4 for i in range(len(seasons))])\n",
    "# first_trials = alien_sum[season_changes]\n",
    "# first_trial_mask = np.array([np.any(alien_trial == first_trials) for alien_trial in alien_sum])\n",
    "\n",
    "# # Subset data\n",
    "# first_aliens = aliens[first_trial_mask]\n",
    "# first_actions = actions[first_trial_mask]\n",
    "# first_TSs = TSs[first_trial_mask]\n",
    "\n",
    "# # Get chosen TS\n",
    "# key = ('TS0', 'TS1', 'TS2', 'TS02', 'TS12', 'None')\n",
    "# chosen_TS_ii = [[get_chosen_TS(alien, action, task.TS, key) for alien, action in zip(first_alien, first_action)]\n",
    "#              for first_alien, first_action in zip(first_aliens, first_actions)]\n",
    "\n",
    "# # Format result\n",
    "# chosen_TS_indiv = np.mean(np.array(chosen_TS_ii), axis=0)  # average over trials to get one row per participant\n",
    "# chosen_TS = pd.DataFrame(data=np.mean(chosen_TS_indiv, axis=0),\n",
    "#                             index=['{}_first_{}'.format(phase_initial, k) for k in key])\n",
    "# chosen_TS_se = pd.DataFrame(data=np.std(chosen_TS_indiv, axis=0),\n",
    "#                                index=['{}_first_{}_se'.format(phase_initial, k) for k in key])\n",
    "\n",
    "subj = 0\n",
    "'true TS:', task.TS, \\\n",
    "'aliens:', np.array([trial[subj] for trial in first_aliens]), \\\n",
    "'actions:', np.array([trial[subj] for trial in first_actions]), \\\n",
    "'inferred TS:', [trial[subj] for trial in chosen_TS_ii], \\\n",
    "'chosen TS:', first_TSs[:, subj]\n",
    "\n",
    "# from collections import Counter\n",
    "# Counter(list(first_TSs.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_name)\n",
    "# phase = '1InitialLearn'  # '2CloudySeason', '1InitialLearn'\n",
    "\n",
    "# params = np.random.rand(len(param_names))\n",
    "# seasons, corrects, rewards, aliens, actions, TSs = get_summary(\n",
    "#             params, param_ranges, n_sim, n_subj, model_name, summary_or_fulldata='fulldata')\n",
    "\n",
    "# # Subset data\n",
    "# seasons, corrects, aliens, actions, TSs = seasons[trials[phase]], corrects[trials[phase]], aliens[trials[phase]], actions[trials[phase]], TSs[trials[phase]]\n",
    "\n",
    "# # Set up regression model correct ~ action_values + TS_values\n",
    "# subj = 0\n",
    "# action_values, TS_values = get_action_TS_values(seasons[:, subj], aliens[:, subj], task.TS)\n",
    "# action_values[:10], TS_values[:10], seasons[:, subj][:10], aliens[:, subj][:10]\n",
    "\n",
    "c = corrects.astype(int)\n",
    "Qa = np.array([get_action_values(seasons[trial], aliens[trial], task.TS) for trial in range(len(seasons))])  # trial x subj\n",
    "Qts = np.array([get_TS_values(seasons[trial], task.TS) for trial in range(len(seasons))])  # trial x subj\n",
    "Qa, Qts, seasons, aliens\n",
    "\n",
    "c.shape, Qa.shape, Qts.shape\n",
    "\n",
    "c_subj = c[:, subj]\n",
    "Qa_subj = Qa[:, subj]\n",
    "Qts_subj = Qts[:, subj]\n",
    "c_subj, Qa_subj, Qts_subj\n",
    "c_subj.reshape(-1, 1)\n",
    "\n",
    "# Qa_subj.shape, c_subj.shape, \n",
    "X_subj = np.array([Qa_subj, Qts_subj]).T\n",
    "y_subj = c[:, subj]\n",
    "\n",
    "X_subj, y_subj\n",
    "\n",
    "regr = LogisticRegression()\n",
    "regr.fit(X_subj, y_subj)\n",
    "regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model_name)\n",
    "params = np.random.rand(len(param_names))\n",
    "seasons, corrects, rewards, aliens, actions, TSs = get_summary(\n",
    "            params, param_ranges, n_sim, n_subj, model_name, summary_or_fulldata='fulldata')\n",
    "\n",
    "# Run regression model correct ~ action_values + TS_values\n",
    "regr_phases = ['1InitialLearn', '2CloudySeason']\n",
    "\n",
    "regr_coeffs = []\n",
    "for phase in regr_phases:\n",
    "\n",
    "    # Get data\n",
    "    seasons_ph, corrects_ph, aliens_ph, actions_ph, TSs_ph = seasons[trials[phase]], corrects[trials[phase]], aliens[trials[phase]], actions[trials[phase]], TSs[trials[phase]]\n",
    "    c = corrects_ph.astype(int)\n",
    "    Qa = np.array([get_action_values(seasons_ph[trial], aliens_ph[trial], task.TS) for trial in range(len(seasons_ph))])  # trial x subj\n",
    "    Qts = np.array([get_TS_values(seasons_ph[trial], task.TS) for trial in range(len(seasons_ph))])  # trial x subj\n",
    "\n",
    "    # Run model for each agent\n",
    "    coefs = []\n",
    "    for subj in range(c.shape[1]):\n",
    "        c_subj = c[:, subj]\n",
    "        Qa_subj = Qa[:, subj]\n",
    "        Qts_subj = Qts[:, subj]\n",
    "\n",
    "        X_subj = np.array([Qa_subj, Qts_subj]).T\n",
    "        y_subj = c[:, subj]\n",
    "\n",
    "        X_subj, y_subj\n",
    "\n",
    "        regr = LogisticRegression(solver='lbfgs')\n",
    "        regr.fit(X_subj, y_subj)\n",
    "        coefs += [regr.coef_.flatten()]\n",
    "        \n",
    "    coefs = pd.DataFrame(\n",
    "        data=np.concatenate([np.mean(np.array(coefs), axis=0), np.std(np.array(coefs), axis=0)]),\n",
    "        index=['{}_{}{}'.format(q, p, s) for q, p, s in zip(2 * ['Qa', 'Qts'], 4 * [phase], 2 * ['_mean'] + 2 * ['_se'])])\n",
    "    regr_coeffs += [coefs]\n",
    "\n",
    "pd.concat(regr_coeffs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['{}_{}{}'.format(q, p, s) for q, p, s in zip(2 * ['Qa', 'Qts'], 4 * [phase], 2 * [''] + 2 * ['_se'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_coefs = np.mean(np.array(coefs), axis=0)\n",
    "std_coefs = np.std(np.array(coefs), axis=0)\n",
    "\n",
    "np.concatenate([mean_coefs, std_coefs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "clf.predict(X[:2, :])\n",
    "\n",
    "clf.predict_proba(X[:2, :])\n",
    "\n",
    "clf.score(X, y)\n",
    "\n",
    "X.shape, y.shape\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.random.rand(len(param_names))\n",
    "get_summary(\n",
    "            params, param_ranges, n_sim, n_subj, model_name, summary_or_fulldata='summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_diff_hist(all_summaries, col_names, model1_name, model2_name, plot_name='test.png', n_bins=50):\n",
    "\n",
    "    all_diff_dat = pd.DataFrame()\n",
    "\n",
    "    for col_name in col_names:\n",
    "        dat1 = all_summaries.loc[all_summaries.model==model1_name, col_name].values\n",
    "        dat2 = all_summaries.loc[all_summaries.model==model2_name, col_name].values\n",
    "\n",
    "        diff_dat = get_difference_data(dat1, dat2, n_bins=n_bins)\n",
    "        diff_dat['measure'] = col_name\n",
    "\n",
    "        all_diff_dat = all_diff_dat.append(diff_dat)\n",
    "\n",
    "    g = (gg.ggplot(all_diff_dat, gg.aes('bin', 'diff', color='measure'))\n",
    "     + gg.geom_line()\n",
    "     + gg.xlab(col_name)\n",
    "     + gg.ylab('Density {} minus {}'.format(model2_name, model1_name))\n",
    "#      + gg.coord_cartesian(xlim=xlim, ylim=ylim)\n",
    "    )\n",
    "    save_path = os.path.join(plot_save_dir, plot_name)\n",
    "    print(\"Saving to {}.\".format(save_path))\n",
    "    g.draw()\n",
    "    g.save(save_path)\n",
    "    \n",
    "# Example use\n",
    "for phase in ['1InitialLearn', '2CloudySeason']:\n",
    "    make_diff_hist(all_summaries,\n",
    "                   ['Qts_{}_mean'.format(phase), 'Qa_{}_mean'.format(phase)],\n",
    "                   'flat', 'hier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusable histogram function for all histogram plots\n",
    "def make_histogram(sim_dat, hum_dat, columns,\n",
    "                   xlabels=False, ylabel=\"Density\", xlim=False, ylim=False, vline=False, yscale_log=False, scale_data=1, plot_name=''):\n",
    "    \n",
    "    nrows = max(len(columns), 2)\n",
    "    fig, axes = plt.subplots(nrows=nrows, figsize=(6, nrows * 2))\n",
    "    [ax.set_ylabel(ylabel) for ax in axes]\n",
    "    \n",
    "    if not xlabels:\n",
    "        xlabels = columns\n",
    "    \n",
    "    for i, (effect, xlabel) in enumerate(zip(columns, xlabels)):\n",
    "        for model in models:\n",
    "            dat = sim_dat.loc[sim_dat['model'] == model]\n",
    "            sns.distplot(scale_data*dat[effect], kde=True, hist=False, label=model, ax=axes[i], bins=19)\n",
    "        if np.any(hum_dat):\n",
    "            axes[i].axvline(x=scale_data*hum_dat[effect].values, color='m', linestyle='-')\n",
    "        axes[i].set_xlabel(xlabel)\n",
    "    \n",
    "    if vline:\n",
    "        [ax.axvline(x=vline, color='grey', linestyle='--') for ax in axes]\n",
    "    if xlim:\n",
    "        [ax.set_xlim(xlim) for ax in axes]\n",
    "    if ylim:\n",
    "        [ax.set_ylim(ylim) for ax in axes]\n",
    "    if yscale_log:\n",
    "        [ax.set_yscale('log') for ax in axes]\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    figure_path = os.path.join(plot_save_dir, plot_name)\n",
    "    plt.savefig(figure_path)\n",
    "    print(\"Saved figure to {}\".format(figure_path))\n",
    "\n",
    "def get_means_sds(sim_dat, hum_dat, column, t_compare_value=0):\n",
    "    \n",
    "    means_sds = sim_dat.groupby(\"model\")[column].agg(\n",
    "        {'mean': 'mean',\n",
    "         'std': 'std',\n",
    "         'lik': lambda x: np.mean(x > hum_dat[column][0]),\n",
    "         'lik2': lambda x: np.mean(x < hum_dat[column][0])})\n",
    "    \n",
    "    ttests = sim_dat.groupby('model')[column].agg(stats.ttest_1samp, t_compare_value)\n",
    "    \n",
    "    return means_sds, ttests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Intrusion error heatmap (prev_TS)\n",
    "# fig = plt.figure(figsize=(10, 5))\n",
    "# for i, effect in enumerate(['IL_acc_prev_TS', 'IL_acc_current_TS']):\n",
    "\n",
    "#     # Subset data with human-like behavior\n",
    "#     dat = all_summaries.loc[(all_summaries['model'] == 'hier') &\n",
    "#                             (all_summaries['IL_acc_prev_TS'] > 0.55)]\n",
    "\n",
    "#     # Plot raw parameters\n",
    "#     ax = fig.add_subplot(2, 3, (i*3)+1, projection='3d')\n",
    "#     ax.set_title(effect)\n",
    "#     ax.scatter(dat['alpha'], dat['beta'], dat['forget'], c=dat[effect], label=dat[effect], marker='.')\n",
    "#     ax.set_xlabel('alpha')\n",
    "#     ax.set_ylabel('beta')\n",
    "#     ax.set_zlabel('forget')\n",
    "\n",
    "#     ax = fig.add_subplot(2, 3, (i*3)+2, projection='3d')\n",
    "#     ax.set_title(effect)\n",
    "#     ax.scatter(dat['alpha_high'], dat['beta_high'], dat['forget_high'], c=dat[effect], label=dat[effect], marker='.')\n",
    "#     ax.set_xlabel('alpha_high')\n",
    "#     ax.set_ylabel('beta_high')\n",
    "#     ax.set_zlabel('forget_high')\n",
    "\n",
    "#     if do_isomap:\n",
    "#         # Dimensionality reduction\n",
    "#         n_neighbors = 12\n",
    "#         n_components = 3\n",
    "#         params_norm = preprocessing.StandardScaler().fit_transform(dat[param_names])  # standardize data\n",
    "#         Y = manifold.Isomap(n_neighbors, n_components).fit_transform(params_norm)  # apply Isomap\n",
    "\n",
    "#         # Plot dimensionality-reduced parameters\n",
    "#         ax = fig.add_subplot(2, 3, (i*3)+3, projection='3d')\n",
    "#         ax.set_title(\"Isomap \" + effect)\n",
    "#         ax.scatter(Y[:, 0], Y[:, 1], Y[:, 2], c=dat[effect], marker='.')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate Isomap & Co. and visualize\n",
    "# params_norm = preprocessing.StandardScaler().fit_transform(dat[param_names])  # standardize data\n",
    "# effect = dat['IL_acc_prev_TS']\n",
    "# fig = plt.figure(figsize=(15, 5))\n",
    "#\n",
    "# i = 1\n",
    "# for n_components in range(2, 6, 2):\n",
    "#     for n_neighbors in range(2, 20, 3):\n",
    "#\n",
    "#         # Reduce dimensionality\n",
    "#         # Y = decomposition.PCA(n_components).fit_transform(params_norm)\n",
    "#         # mds = manifold.MDS(n_neighbors, max_iter=100, n_init=1)\n",
    "#         # Y = mds.fit_transform(params_norm)\n",
    "#         # Y = manifold.LocallyLinearEmbedding(n_neighbors, n_components, eigen_solver='auto',\n",
    "#         #                                     method='standard').fit_transform(params_norm)\n",
    "#         # Y = manifold.LocallyLinearEmbedding(n_neighbors, n_components, eigen_solver='auto',  # n_neighbors >= 6\n",
    "#         #                                     method='modified').fit_transform(params_norm)\n",
    "#         Y = manifold.Isomap(n_neighbors, n_components).fit_transform(params_norm)\n",
    "#\n",
    "#         # Plot\n",
    "#         ax = fig.add_subplot(2, 6, i)\n",
    "#         plt.scatter(Y[:, 0], Y[:, 1], c=effect)\n",
    "#         plt.title('{0} comp., {1} neigh.'.format(n_components, n_neighbors))\n",
    "#         i += 1\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Intrusion error heatmap (other TS)\n",
    "fig = plt.figure()\n",
    "for i, effect in enumerate(['IL_acc_other_TS', 'IL_acc_current_TS']):\n",
    "\n",
    "    dat = all_summaries.loc[(all_summaries['model'] == 'hier') &\n",
    "                            (all_summaries['IL_acc_other_TS'] > 1/3)]\n",
    "\n",
    "    ax = fig.add_subplot(2, 2, i+1, projection='3d')\n",
    "    ax.set_title(effect)\n",
    "    ax.scatter(dat['alpha'], dat['beta'], dat['forget'], c=dat[effect], label=dat[effect], marker='.')\n",
    "    ax.set_xlabel('alpha')\n",
    "    ax.set_ylabel('beta')\n",
    "    ax.set_zlabel('forget')\n",
    "\n",
    "    ax = fig.add_subplot(2, 2, i+3, projection='3d')\n",
    "    ax.set_title(effect)\n",
    "    ax.scatter(dat['alpha_high'], dat['beta_high'], dat['forget_high'], c=dat[effect], label=dat[effect], marker='.')\n",
    "    ax.set_xlabel('alpha_high')\n",
    "    ax.set_ylabel('beta_high')\n",
    "    ax.set_zlabel('forget_high')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Savings heatmap\n",
    "fig = plt.figure()\n",
    "for i, effect in enumerate(['IL_saving_av', 'IL_saving_first_trial', 'IL_saving_last_trial', 'IL_saving_last_minus_first']):\n",
    "\n",
    "    dat = all_summaries.loc[(all_summaries['model'] == 'hier') &\n",
    "                            (all_summaries['IL_saving_last_trial'] > 0.01) & (all_summaries['IL_saving_first_trial'] > 0.08)]\n",
    "\n",
    "    ax = fig.add_subplot(2, 4, i+1, projection='3d')\n",
    "    ax.set_title(effect)\n",
    "    ax.scatter(dat['alpha'], dat['beta'], dat['forget'], c=dat[effect], label=dat[effect], marker='.')\n",
    "    ax.set_xlabel('alpha')\n",
    "    ax.set_ylabel('beta')\n",
    "    ax.set_zlabel('forget')\n",
    "\n",
    "    ax = fig.add_subplot(2, 4, i+5, projection='3d')\n",
    "    ax.set_title(effect)\n",
    "    ax.scatter(dat['alpha_high'], dat['beta_high'], dat['forget_high'], c=dat[effect], label=dat[effect], marker='.')\n",
    "    ax.set_xlabel('alpha_high')\n",
    "    ax.set_ylabel('beta_high')\n",
    "    ax.set_zlabel('forget_high')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Cloudy heatmap\n",
    "fig = plt.figure()\n",
    "for i, effect in enumerate(['CL_acc_trial2', 'CL_acc_trial3']):\n",
    "\n",
    "    dat = all_summaries.loc[(all_summaries['model'] == 'hier') &\n",
    "                            (all_summaries['CL_acc_trial2'] > 0.4) & (all_summaries['CL_acc_trial3'] > 0.4)]\n",
    "\n",
    "    ax = fig.add_subplot(2, 2, i+1, projection='3d')\n",
    "    ax.set_title(effect)\n",
    "    ax.scatter(dat['alpha'], dat['beta'], dat['forget'], c=dat[effect], label=dat[effect], marker='.')\n",
    "    ax.set_xlabel('alpha')\n",
    "    ax.set_ylabel('beta')\n",
    "    ax.set_zlabel('forget')\n",
    "\n",
    "    ax = fig.add_subplot(2, 2, i+3, projection='3d')\n",
    "    ax.set_title(effect)\n",
    "    ax.scatter(dat['alpha_high'], dat['beta_high'], dat['forget_high'], c=dat[effect], label=dat[effect], marker='.')\n",
    "    ax.set_xlabel('alpha_high')\n",
    "    ax.set_ylabel('beta_high')\n",
    "    ax.set_zlabel('forget_high')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Competition heatmap\n",
    "fig = plt.figure()\n",
    "for i, effect in enumerate(['CO_acc_season', 'CO_acc_season_alien']):\n",
    "\n",
    "    dat = all_summaries.loc[(all_summaries['model'] == 'hier') &\n",
    "                            (all_summaries['CO_acc_season'] > 0.65)]  #  &(all_summaries['CO_acc_season_alien'] > 0.60)\n",
    "\n",
    "    ax = fig.add_subplot(2, 2, i+1, projection='3d')\n",
    "    ax.set_title(effect)\n",
    "    ax.scatter(dat['alpha'], dat['beta'], dat['forget'], c=dat[effect], label=dat[effect], marker='.')\n",
    "    ax.set_xlabel('alpha')\n",
    "    ax.set_ylabel('beta')\n",
    "    ax.set_zlabel('forget')\n",
    "\n",
    "    ax = fig.add_subplot(2, 2, i+3, projection='3d')\n",
    "    ax.set_title(effect)\n",
    "    ax.scatter(dat['alpha_high'], dat['beta_high'], dat['forget_high'], c=dat[effect], label=dat[effect], marker='.')\n",
    "    ax.set_xlabel('alpha_high')\n",
    "    ax.set_ylabel('beta_high')\n",
    "    ax.set_zlabel('forget_high')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Rainbow heatmap\n",
    "fig = plt.figure()\n",
    "for i, effect in enumerate(['RB_choices_TS0', 'RB_choices_TS1', 'RB_choices_TS2']):\n",
    "\n",
    "    dat = all_summaries.loc[(all_summaries['model'] == 'hier') &\n",
    "                            (all_summaries['RB_choices_TS0'] > 1300) & (all_summaries['RB_choices_TS1'] > 1000)]\n",
    "\n",
    "    ax = fig.add_subplot(2, 3, i+1, projection='3d')\n",
    "    ax.set_title(effect)\n",
    "    ax.scatter(dat['alpha'], dat['beta'], dat['forget'], c=dat[effect], label=dat[effect], marker='.')\n",
    "    ax.set_xlabel('alpha')\n",
    "    ax.set_ylabel('beta')\n",
    "    ax.set_zlabel('forget')\n",
    "\n",
    "    ax = fig.add_subplot(2, 3, i+4, projection='3d')\n",
    "    ax.set_title(effect)\n",
    "    ax.scatter(dat['alpha_high'], dat['beta_high'], dat['forget_high'], c=dat[effect], label=dat[effect], marker='.')\n",
    "    ax.set_xlabel('alpha_high')\n",
    "    ax.set_ylabel('beta_high')\n",
    "    ax.set_zlabel('forget_high')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Plot overall heatmaps -> systematicity between parameters & effects?\n",
    "for effect in summary_dat_cols:\n",
    "    fig = plt.figure()\n",
    "    plt.title(effect)\n",
    "    for i, model in enumerate(models):\n",
    "        dat = all_summaries.loc[all_summaries['model'] == model][:1000].copy()\n",
    "\n",
    "        ax = fig.add_subplot(2, 2, i+1, projection='3d')\n",
    "        ax.scatter(dat['alpha'], dat['beta'], dat['forget'], c=dat[effect], label=dat[effect], marker='.')\n",
    "        ax.set_title(model)\n",
    "        ax.set_xlabel('alpha')\n",
    "        ax.set_ylabel('beta')\n",
    "        ax.set_zlabel('forget')\n",
    "\n",
    "        ax = fig.add_subplot(2, 2, i+3, projection='3d')\n",
    "        ax.scatter(dat['alpha_high'], dat['beta_high'], dat['forget_high'], c=dat[effect], label=dat[effect], marker='.')\n",
    "        ax.set_xlabel('alpha_high')\n",
    "        ax.set_ylabel('beta_high')\n",
    "        ax.set_zlabel('forget_high')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Plot average effects for hierarchical and flat\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    dat = all_summaries.loc[all_summaries['model'] == model].copy()\n",
    "    RB_effects = [effect for effect in all_summaries.columns.values if 'RB' in effect]\n",
    "\n",
    "    dat[RB_effects] /= 1000\n",
    "    dat['beta'] /= 10\n",
    "    x = np.arange(len(summary_dat_cols)) + 0.2 * (2*i-1)\n",
    "    y = np.mean(dat[summary_dat_cols], axis=0)\n",
    "    yerr = np.std(dat[summary_dat_cols], axis=0) / np.sqrt(len(summary_dat_cols))\n",
    "\n",
    "    ax.bar(x, y.values, 0.4, yerr=yerr, label=model)\n",
    "ax.set_xticks(np.arange(len(summary_dat_cols)))\n",
    "ax.set_xticklabels(summary_dat_cols)\n",
    "plt.xticks(rotation=20)\n",
    "plt.ylabel('Effect (RB /= 1000)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Double-check selected hier-agent summary\n",
    "# # summary_save_dir_ag = os.path.join(get_alien_paths(run_on_cluster)['fitting results'], 'SummariesInsteadOfFitting')  # Where will the simulated summary data be saved and read from?\n",
    "# params = pd.read_csv(old_summary_save_dir + '/ag_summary_for_paper.csv', index_col=0).loc[param_names]\n",
    "# params_01 = params.values.flatten() / (param_ranges.loc[1] - param_ranges.loc[0]) - param_ranges.loc[0] / (\n",
    "#             param_ranges.loc[1] - param_ranges.loc[0])\n",
    "# # params_back = param_ranges.loc[0] + (param_ranges.loc[1] - param_ranges.loc[0]) * params_01  # making sure i'm getting the right parameters back after transformation!\n",
    "\n",
    "# summary = get_summary(params_01.values.flatten(), param_ranges, n_sim, n_subj)\n",
    "# summary = pd.DataFrame(summary, index=summary_dat_cols).transpose()\n",
    "\n",
    "# summary  # check that it agrees with what we have in the paper! (This is just to double-check that I'm using the right parameters for the simulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hum_summary_initial_learn['source'] = 'human'\n",
    "hum_summary_initial_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_summary['source'] = 'simulation'\n",
    "sim_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hum_and_sim = hum_summary_initial_learn.append(sim_summary, sort=False)\n",
    "hum_and_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['IL_acc_prev_TS', 'IL_acc_current_TS']\n",
    "intr_dat = hum_and_sim[cols + ['{}_se'.format(col) for col in cols] + ['source']]\n",
    "intr_long = pd.melt(intr_dat, id_vars='source')\n",
    "\n",
    "(gg.ggplot(intrerr_dat, gg.aes('')))\n",
    "\n",
    "# intrerr_dat\n",
    "intr_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hum_and_sim_long = pd.melt(hum_and_sim, id_vars='source')\n",
    "(gg.ggplot(hum_and_sim_long, gg.aes('variable', 'value', color='source'))\n",
    " + gg.geom_point()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYMC3",
   "language": "python",
   "name": "pymc3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
